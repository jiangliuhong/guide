[{"id":0,"href":"/docs/java/jvm/","title":"jvm","section":"Java","content":" jvm # jvm 调优 # "},{"id":1,"href":"/docs/middleware/messagequeue/","title":"消息中间件","section":"Docs","content":" 消息中间件 # 消息队列设计精要 # 使用消息队列的常见场景主要有业务解耦、最终一致性、错峰流控等。\n解耦：消息队列要解决的本质问题，各个组件之间，不再显示依赖，只需要做到消息发送成功。\n最终一致性：使得所有系统结果保持一致，要么都成功，要么都失败。在使用消息队列处理最终一致性问题时，往往是对失败的消息进行重试操作，直到成功为止（这里需要要求幂等性）。同时对于始终不成功的消息，也需要增加补偿操作，进一步保证最终一致性。\n错峰流控：对于一些并发较大的操作，如果一同进行，可能导致应用无法承受而宕机，加入消息队列后，可以在消费者处进行限制，按照消费者能力对消息进行处理，同时由于消息队列集群消费的特性，也可以根据消息的实际情况，按需增删消费者实例。\n对于一个消息队列而言，它应该具有的功能有：\n参考链接：https://tech.meituan.com/2016/07/01/mq-design.html\n为什么使用mq # rocketmq # "},{"id":2,"href":"/docs/database/redis/core/","title":"Redis核心知识","section":"Redis","content":" 核心知识 # 持久化 # redis 提供了两种持久化的方式，分别是RDB（Redis DataBase）和AOF（Append Only File）。\nRDB，简而言之，就是在不同的时间点，将 redis 存储的数据生成快照并存储到磁盘等介质上；\nAOF，则是换了一个角度来实现持久化，那就是将 redis 执行过的所有写指令记录下来，在下次 redis 重新启动时，只要把这些写指令从前到后再重复执行一遍，就可以实现数据恢复了。\n其实 RDB 和 AOF 两种方式也可以同时使用，在这种情况下，如果 redis 重启的话，则会优先采用 AOF 方式来进行数据恢复，这是因为 AOF 方式的数据恢复完整度更高。\n如果你没有数据持久化的需求，也完全可以关闭 RDB 和 AOF 方式，这样的话，redis 将变成一个纯内存数据库，就像 memcache 一样。\nRDB # RDB 是将redis的某一时刻的数据持久化到磁盘中，是一种快照式的持久化方法。\nredis在进行数据持久化的过程中，会先将数据写入到一个临时文件中，待持久化过程完成，才会将此文件替换为最终的持久化文件。\n对于 RDB 模式，redis会单独创建一个子进程进行持久化操作，不会有主进程介入，从而保证redis的性能。\n如果需要进行大规模的数据存储与恢复，那么 RDB 方式是当仁不让的，不过 RDB 的缺点也较为明显：\n在redis中，RDB 是默认开启的，默认为每 900 秒内1 次修改、300 秒内 10 此修改、60 秒内 10000次修改进行一次 RDB 备份操作（可以通过save 900 1的方式修改频率），当redis故障时，根据备份的时间点，总会可能存在数据的丢失。 save 频率较高时，频繁写入磁盘，会造成磁盘压力过大，同时多个子进程之间相互竞争服务器 CPU、磁盘资源。 虽然 RDB 备份是通过子进程实现，但如果频繁主进程创建子进程进行操作，也会对主进程造成阻塞。 AOF # 上面提到 RDB 模式不可避免会存在数据丢失的情况，对于解决这一问题，可以使用 AOF 备份方式，AOF 是将redis执行过程的指令都记录下来，在数据恢复时，按照从前到后的顺序再将指令执行一次。\n在redis中，通过修改appendonly yes配置可打开 AOF 备份。\n在redis中，AOF 的持久化策略有三种：\nEverysec，每秒写回，redis默认的配置，每秒执行一次fsync(fsync是指吧缓存中的写指令记录到磁盘中)，所以即使redis故障，也只会丢失 1 秒钟的数据。 Always，同步写回，每次执行命令都需要执行fsync，对redis性能影响较大。 No，操作系统控制写回，这一方式性能较高，但是宕机时丢失数据可能较多。 由于 AOF 是追加日志的方式，如果不做干预的话，AOF 文件将会越来越大，备份恢复时间也会越来越长，对于这个问题，redis提供了 AOF 文件重写机制，当 AOF 文件的大小超过设定的阈值时，redis 会对AOF文件的内容进行压缩，只保留恢复数据的最小指令集。\nAOF 文件压缩示例：用户调用了 100 次 INCR 指令，此时进行压缩后，只会存在一个 SET 指令。\n在重写时，如果有新的操作，redis会讲新的操作记录到新的日志文件中，待重写完成再对文件进行合并操作。\n混合模式 # 从redis4.0开始支持混合型持久化模式。在 4.0 时提出创建一个同时包含rdb数据和aof数据的文件（其中rdb数据在前，aof数据在后）用于存储服务器开始执行重写操作时的数据库状态。\n混合模式下，内存快照以一定频率进行，然后在两次快照之间，使用aof日志记录两次快照期间所有的命令操作。\n在混合模式下，既能享受 RDB 文件快速恢复的好处，也能享受到 AOF 只记录操作命令的简单优势。\n在redis4.0时，需要通过aof-use-rdb-preamble yes配置开启混合模式，但是在redis5.0时，redis已经将混合模式设置为默认的持久化方案。\n持久化恢复 # 对于 RDB 和 AOF 而言，持久化的恢复较为简单。\n在加入混合模式后，持久化的恢复，需要同时兼顾 RDB 与 AOF，混合模式的恢复流程如下：\n发布订阅 # TODO\n基于频道\n基于模式\n事件机制 # redis事件包含两部分：\n文件事件：用于处理 Redis 服务器和客户端之间的网络IO。 时间事件：Redis 服务器中的一些操作（比如serverCron函数）需要在给定的时间点执行，而时间事件就是处理这类定时操作的。 事务 # redis 事务的本质是一组命令的集合。事务支持一次执行多个命令，一个事务中所有命令都会被序列化。在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。\nredis事务就是一次性、顺序性、排他性的执行一个队列中的一系列命令。\nredis事务相关的命令：\nMULTI ：开启事务，redis会将后续的命令逐个放入队列中，然后使用EXEC命令来原子化执行这个命令系列。 EXEC：执行事务中的所有操作命令。 DISCARD：取消事务，放弃执行事务块中的所有命令。 WATCH：监视一个或多个key,如果事务在执行前，这个key(或多个key)被其他命令修改，则事务被中断，不会执行事务中的任何命令。 UNWATCH：取消WATCH对所有key的监视。 CAS 操作实现乐观锁 # 在redis中可以使用watch命令实现cas乐观锁，利用watch的特性，首先对某个key进行watch，开启事务修改key，如果此时该key被其他客户端修改，那么当前事务将会无效，在 java中代码如下：\npublic void delete(String key, String value) { jedis.watch(key); if (value.equals(jedis.get(key))) { Transaction tx = jedis.multi(); tx.del(key); tx.exec(); } else { jedis.unwatch(); } } "},{"id":3,"href":"/docs/database/redis/data/","title":"Redis数据结构","section":"Redis","content":" 数据结构 # 数据类型 # 5种基本类型 # 5 种常见的基本类型有：String、List、Set、Zset、Hash\n类型 存储的值 读写能力 String 字符串、整数或浮点数 对整个字符串或字符串的一部分进行操作；对整数或者浮点数进行自增或自减操作 List 链表，链表每个节点都是一个字符串 对链表的两端进行push和pop操作，读取单个或者多个元素；根据值查找或删除元素 Set 字符串的无序集合 字符串的集合，基础操作有添加、删除、获取；同时还有计算交集、并集、差集等 Hash 包含键值对的无序散列表 基本方法有添加、获取、删除单个元素方法 Zset 与Hash相同，用于存储键值对 字符串成员与浮点数之间的有序映射，元素的排列顺序由分数的大小决定；基本方法有添加、获取、删除单个元素以及根据分数范围或成员来获取元素 String # String是redis中最基本的数据类型，一个key对应一个value。\nString类型是二进制安全的，意思是 redis 的 string 可以包含任何数据。如数字，字符串，jpg图片或者序列化的对象。\nString类型的常用操作有：\n命令 简述 使用 GET 获取存储在给定键中的值 GET name SET 设置存储在给定键中的值 SET name value DEL 删除存储在给定键中的值 DEL name INCR 将键存储的值加1 INCR key DECR 将键存储的值减1 DECR key INCRBY 将键存储的值加上整数 INCRBY key amount DECRBY 将键存储的值减去整数 DECRBY key amount 更加详细的string操作参考：https://www.redis.net.cn/order/3544.html\nstring的常用场景：\n缓存：把常用信息，字符串，图片或者视频等信息放到redis中，redis作为缓存层，mysql做持久化层，降低mysql的读写压力 计数器：redis是单线程模型，一个命令执行完才会执行下一个，同时数据可以一步落地到其他的数据源。 session：常见方案spring session + redis实现session共享， List # List是redis中的链表，在redis中是使用双端链表实现的。\n使用List结构，我们可以轻松地实现最新消息排队功能（比如新浪微博的TimeLine）。\nList的另一个应用就是消息队列，可以利用List的 PUSH 操作，将任务存放在List中，然后工作线程再用 POP 操作将任务取出进行执行。\nList类型的常用操作有：\n命令 简述 使用 RPUSH 将给定值推入到列表右端 RPUSH key value LPUSH 将给定值推入到列表左端 LPUSH key value RPOP 从列表的右端弹出一个值，并返回被弹出的值 RPOP key LPOP 从列表的左端弹出一个值，并返回被弹出的值 LPOP key LRANGE 获取列表在给定范围上的所有值 LRANGE key 0 -1 LINDEX 通过索引获取列表中的元素。你也可以使用负数下标，以 -1 表示列表的最后一个元素， -2 表示列表的倒数第二个元素，以此类推。 LINDEX key index LTRIM 让列表只保留指定区间内的元素，不在指定区间之内的元素都将被删除 LTRIM KEY_NAME START STOP BRPOP 移出并获取列表的最后一个元素， 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止 BRPOP LIST1 LIST2 .. LISTN TIMEOUT 更加详细的list操作参考：https://www.redis.net.cn/order/3577.html\n使用技巧：\n作为桟使用：lpush + lpop 作为队列使用：lpush + rpop 作为有限集合使用：lpush + ltrim 作为消息队列使用：lpoush + brpop list的常用场景：\n微博TimeLine: 有人发布微博，用lpush加入时间轴，展示新的列表信息。 消息队列 Set # Redis 的 Set 是 String 类型的无序集合。集合成员是唯一的，这就意味着集合中不能出现重复的数据。\nRedis 中集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是 O(1)。\nSet类型的常用操作有：\n命令 简述 使用 SADD 向集合添加一个或多个成员 SADD key value SCARD 获取集合的成员数 SCARD key SMEMBERS 返回集合中的所有成员 SMEMBERS key member SISMEMBER 判断 member 元素是否是集合 key 的成员 SISMEMBER key member 更加详细的set操作参考：https://www.redis.net.cn/order/3594.html\nset的常用场景：\n标签（tag）,给用户添加标签，或者用户给消息添加标签，这样有同一标签或者类似标签的可以给推荐关注的事或者关注的人。 点赞，或点踩，收藏等，可以放到set中实现 Hash # Redis hash 是一个 string 类型的 field（字段） 和 value（值） 的映射表，hash 特别适合用于存储对象。\nhash类型的常用操作有：\n命令 简述 使用 HSET 添加键值对 HSET hash-key sub-key1 value1 HGET 获取指定散列键的值 HGET hash-key key1 HGETALL 获取散列中包含的所有键值对 HGETALL hash-key HDEL 如果给定键存在于散列中，那么就移除这个键 HDEL hash-key sub-key1 hash 主要是和维护对象信息，使缓存数据更加直观，同时也不string更节省空间。\n更加详细的hash操作参考：https://www.redis.net.cn/order/3564.html\nZset # Redis 有序集合和集合一样也是 string 类型元素的集合,且不允许重复的成员。\n不同的是每个元素都会关联一个 double 类型的分数。redis 正是通过分数来为集合中的成员进行从小到大的排序。\n有序集合的成员是唯一的, 但分数(score)却可以重复。有序集合是通过两种数据结构实现：\n压缩列表（ziplist）:为了提高存储效率而设计的一种特殊编码的双向链表。它可以存储字符串或者整数，存储整数时是采用整数的二进制而不是字符串形式存储。它能在O(1)的时间复杂度下完成list两端的push和pop操作。但是因为每次操作都需要重新分配ziplist的内存，所以实际复杂度和ziplist的内存使用量相关。详细说明 跳跃表（zSkiplist）:跳跃表的性能可以保证在查找，删除，添加等操作的时候在对数期望时间内完成，这个性能是可以和平衡树来相比较的，而且在实现方面比平衡树要优雅，这是采用跳跃表的主要原因。跳跃表的复杂度是O(log(n))。详细说明 zset类型的常用操作有：\n命令 简述 使用 ZADD 将一个带有给定分值的成员添加到有序集合里面 ZADD zset-key 178 member1 ZRANGE 根据元素在有序集合中所处的位置，从有序集合中获取多个元素 ZRANGE zset-key 0-1 withccores ZREM 如果给定元素成员存在于有序集合中，那么就移除这个元素 ZREM zset-key member1 更加详细的zset操作参考：https://www.redis.net.cn/order/3609.html\n3种特殊类型 # redis的三种特殊的数据类型，分别是 HyperLogLogs（基数统计）， Bitmaps (位图) 和 geospatial （地理位置）。\nHyperLogLogs（基数统计） # 在redis 2.8.9 版本新增了HyperLogLogs数据结构\nHyperLogLogs可以非常省内存的去做统计计数，比如注册 IP 数、每日访问 IP 数、页面实时 UC、在线用户数，共同好友数等。\n例如要对于一个网站的访问数进行统计，假如每天访问的 IP 有 100 万，一个 IP 消耗 15 字节，那么 100 万个 IP 就是 15M。而使用HyperLogLogs 在redis中每个键咱用的内容都是 12K，理论上存储近视 2^64 个值，不管存储的内容是什么，它基于基数估算的算法，可以使用少量固定的内存去识别集合中的唯一元素。\n需要注意的是，这个估算并不是完全准确的，它拥有0.81%的误差，当然对于一些允许容错的业务场景，这个误差是可以忽略不计的。\nHyperLogLogs类型的常用操作有：\n命令 简述 使用 PFMERGE 将多个 HyperLogLog 合并为一个 HyperLogLog ，合并后的 HyperLogLog 的基数估算值是通过对所有 给定 HyperLogLog 进行并集计算得出的。 PFMERGE destkey sourcekey [sourcekey \u0026hellip;] PFADD 将所有元素参数添加到 HyperLogLog 数据结构中 PFADD key element [element \u0026hellip;] PFCOUNT 返回给定 HyperLogLog 的基数估算值 PFCOUNT key [key \u0026hellip;] Bitmaps (位图) # Bitmap 即位图数据结构，都是操作二进制位来进行记录，只有0 和 1 两个状态。\n常用来存储统计信息，例如统计用户的登录状态、考勤系统记录员工的打卡状态等。\nbitmap类型的常用操作有：\n命令 简述 使用 setbit 设置值 setbit key num 1/0 getbit 获取值 getbit key num bitcount 位统计，获取值为 1 的个数 bitcount key geospatial（地理位置） # Redis 的 Geo 在 Redis 3.2 版本就推出了! 这个功能可以推算地理位置的信息: 两地之间的距离, 方圆几里的人\ngeospatial类型的常用操作有：\n命令 简述 使用 GEOHASH 返回一个或多个位置的hash值,如果字符串越接近则距离越近 GEOHASH Sicily Palermo Catania GEOPOS 从key里返回所有给定位置元素的位置（经度和纬度） GEOPOS Sicily Palermo Catania NonExisting GEODIST 返回两个给定位置之间的距离 GEODIST Sicily Palermo Catania [km/mi] GEORADIUS 以给定的经纬度为中心,找出某一半径内的元素 GEORADIUS Sicily 15 37 200 km WITHCOORD GEOADD 将指定的地理空间位置（纬度、经度、名称）添加到指定的key中 GEOADD Sicily 13.361389 38.115556 \u0026ldquo;Palermo\u0026rdquo; GEORADIUSBYMEMBER 指定成员的位置被用作查询的中心,找出位于指定范围内的元素 GEORADIUSBYMEMBER Sicily Agrigento 100 km stream类型 # stream类型是在redis5.0中新增的，它借鉴了kafka的设计，是redis一个新的、强大的支持多播的可持久化的消息队列。\n在 redis5.0 之前，基于redis实现消息队列的方法都存在一些弊端，比如：\nPUB/SUB 发布订阅模式，无法持久化，如果出现网络问题、redis服务宕机问题，消息则会丢失 List LPUSH + BRPOP 或者 Sorted-Set 的实现，虽然支持了持久化，但是不支持多播、分组消费等 在redis新增stream类型后，基于此类型实现消息队列，虽然并不能实现一个完全体的消息队列，但也能做到一个轻量级的实践，可以满足的需求有：\n消息持久化 消息的基本增删改查操作 单播、多播、组播 监控消息状态 常用命令 # stream类型的常用操作有：\n命令 简述 使用 XADD 添加消息到末尾 XADD key ID field string [field string \u0026hellip;] XGROUP 管理流数据结构关联的消费者组 XGROUP CREATE mystream consumer-group-name XTRIM 对消息进行修剪，限制长度 XTRIM key MAXLEN [~] count XDEL 删除消息 XDEL key ID [ID \u0026hellip;] XLEN 获取消息长度 xlen key XRANGE 获取消息列表，自动过滤已经删除的消息 XRANGE key start end [COUNT count] XREVRANGE 反向获取消息列表 XREVRANGE key end start [COUNT count] XREAD 以阻塞或非阻塞方式获取消息列表 XREAD [COUNT count] [BLOCK milliseconds] STREAMS key [key \u0026hellip;] ID [ID \u0026hellip;] 使用range命令时，可以用 - 表示最小值,用 + 表示最大值\nXGROUP的作用主要有：\n创建与流关联的新消费者组。 销毁一个消费者组。 从消费者组中移除指定的消费者。 将消费者组的最后交付ID设置为其他内容。 更加消息的命令说明参考：http://www.redis.cn/commands/xadd.html\n结构组成 # 对于 stream 类型，每个 stream 都有唯一的名称，它就是 Redis 的 key，在我们首次使用 xadd 指令追加消息时自动创建。\n如图所示，可以清晰的看见，当我们使用stream类型构建消息队列，主要有 3 个要点：\nconsumer group:消费组，使用 XGROUP CREATE命令创建，一个消费组有多个消费者（Consumer），这些消费者彼此之间属于竞争关系 last_delivered_id:游标，每个消费组会有一个游标last_delivered_id,任意一个消费者读取了消息都会使游标last_delivered_id往前移动 pending_ids:消费者的状态变量，作用是维护消费者的未确认的id，记录当前已经被客户端读取的消息，但还没有ack(被确认的标记) 另外，在使用stream结构构建消息队列时，还需要注意：\n消息 ID：消息 ID 的形式是timestampInMillis-sequence，例如1527846880572-5，它表示当前的消息在毫米时间戳1527846880572时产生，并且是该毫秒内产生的第5条消息。消息ID可以由服务器自动生成，也可以由客户端自己指定，但是形式必须是整数-整数，而且必须是后面加入的消息的ID要大于前面的消息ID。 消息内容：消息内容就是键值对，比如hash结构的键值对。 独立消费 # 上面提到的均为针对消费组的情况下进行消费，而strem类型也支持独立消费，redis提供了单独的消费指令 —— XREAD。\n使用xread时，我们可以完全忽略消费组(Consumer Group)的存在，就好比Stream就是一个普通的列表(list)。\n使用xread时，客户端如果想要使用xread进行顺序消费，一定要记住当前消费到哪里了，也就是返回的消息ID。下次继续调用xread时，将上次返回的最后一个消息ID作为参数传递进去，就可以继续消费后续的消息。\nxread的参数，block 0表示永远阻塞，直到消息到来，block 1000表示阻塞1s，如果1s内没有任何消息到来，就返回nil，使用示例：\n从Stream头部读取两条消息：xread count 2 streams codehole 0-0 从Stream尾部读取一条消息，毫无疑问，这里不会返回任何消息：xread count 1 streams codehole $ 从尾部阻塞等待新消息到来，下面的指令会堵住，直到新消息到来：xread block 0 count 1 streams codehole $ 我们从新打开一个窗口，在这个窗口往Stream里塞消息：xadd codehole * name youming age 60 消费组消费 # 消费组相关的命令：\nXGROUP CREATE - 创建消费者组 XREADGROUP GROUP - 读取消费者组中的消息 XACK - 将消息标记为\u0026quot;已处理\u0026quot; XGROUP SETID - 为消费者组设置新的最后递送消息ID XGROUP DELCONSUMER - 删除消费者 XGROUP DESTROY - 删除消费者组 XPENDING - 显示待处理消息的相关信息 XCLAIM - 转移消息的归属权 XINFO - 查看流和消费者组的相关信息； XINFO GROUPS - 打印消费者组的信息； XINFO STREAM - 打印流信息 信息监控 # 使用 XINFO 命令可以对stream进行监控：\n监控队列信息：xinfo stream mq 监控组信息：xinfo groups mq 监控消费组成员信息：xinfo consumers mq mqGroup 相关问题 # 使用场景 # 通信 大数据分析 异地数据备份 消息ID的设计是否考虑了时间回拨的问题 # XADD生成的1553439850328-0，就是Redis生成的消息ID，由两部分组成:时间戳-序号。时间戳是毫秒级单位，是生成消息的Redis服务器时间，它是个64位整型（int64）。序号是在这个毫秒时间点内的消息序号，它也是个64位整型\n可以通过multi批处理，来验证序号的递增：\n127.0.0.1:6379\u0026gt; MULTI OK 127.0.0.1:6379\u0026gt; XADD memberMessage * msg one QUEUED 127.0.0.1:6379\u0026gt; XADD memberMessage * msg two QUEUED 127.0.0.1:6379\u0026gt; XADD memberMessage * msg three QUEUED 127.0.0.1:6379\u0026gt; XADD memberMessage * msg four QUEUED 127.0.0.1:6379\u0026gt; XADD memberMessage * msg five QUEUED 127.0.0.1:6379\u0026gt; EXEC 1) \u0026#34;1553441006884-0\u0026#34; 2) \u0026#34;1553441006884-1\u0026#34; 3) \u0026#34;1553441006884-2\u0026#34; 4) \u0026#34;1553441006884-3\u0026#34; 5) \u0026#34;1553441006884-4\u0026#34; 由于一个redis命令的执行很快，所以可以看到在同一时间戳内，是通过序号递增来表示消息的。为了保证消息是有序的，因此Redis生成的ID是单调递增有序的。由于ID中包含时间戳部分，为了避免服务器时间错误而带来的问题（例如服务器时间延后了），Redis的每个Stream类型数据都维护一个latest_generated_id属性，用于记录最后一个消息的ID。若发现当前时间戳退后（小于latest_generated_id所记录的），则采用时间戳不变而序号递增的方案来作为新消息ID（这也是序号为什么使用int64的原因，保证有足够多的的序号），从而保证ID的单调递增性质。\n消费者崩溃带来的会不会消息丢失问题 # 为了解决组内消息读取但处理期间消费者崩溃带来的消息丢失问题，STREAM 设计了 Pending 列表，用于记录读取但并未处理完毕的消息。命令XPENDIING 用来获消费组或消费内消费者的未处理完毕的消息\n每个Pending的消息有4个属性：\n消息ID 所属消费者 IDLE，已读取时长 delivery counter，消息被读取次数 当消费者下线后再次上线，可以读取该Pending列表，就可以继续处理该消息了，保证消息的有序和不丢失。\n消息转移 # 消息转移即：消费者彻底宕机后转移给其它消费者处理，需要转移的有两个，一个是未消费的消息转移，一个是将宕机的消费者的 Pending消息转移。\n在redis中，可使用 XCLAIM 命令，指定组、消费者、消息 ID 以及 IDLE（以被读取时长，只有超过这个时长，才能被转移），然后就可将这些消息转移到新的消费者的Pending列表中。\n死信问题 # 如果某个消息，不能被消费者处理，也就是不能被XACK，这是要长时间处于Pending列表中，即使被反复的转移给各个消费者也是如此。此时该消息的delivery counter就会累加，当累加到某个我们预设的临界值时，我们就认为是坏消息（也叫死信，DeadLetter，无法投递的消息），由于有了判定条件，我们将坏消息处理掉即可，删除即可。删除一个消息，使用XDEL语法，演示如下：\n# 删除队列中的消息 127.0.0.1:6379\u0026gt; XDEL mq 1553585533795-1 (integer) 1 # 查看队列中再无此消息 127.0.0.1:6379\u0026gt; XRANGE mq - + 1) 1) \u0026#34;1553585533795-0\u0026#34; 2) 1) \u0026#34;msg\u0026#34; 2) \u0026#34;1\u0026#34; 2) 1) \u0026#34;1553585533795-2\u0026#34; 2) 1) \u0026#34;msg\u0026#34; 2) \u0026#34;3\u0026#34; 对象机制 # 在redis中，为了完成对不同类型的键值进行不同的操作，所以redis必须让每个键都带有类型信息，使得程序可以检查键的类型，从而选择合适的处理方式。例如，redis在处理集合类型的时候，集合类型可以由字段和整数集合两种不同的数据结构实现，当用户执行ZADD命令时，无需用户关心集合的底层实现，由redis本身选择合适的方法进行处理。\n即：操作苏剧类型的命令处理要对键的类型进行检查以外，还需要多根据类型的不同编码（不同的底层结构）进行多态处理。\nredis为了实现上面的内容，构建了自己的类型系统，主要包括：\nredisObject对象 基于redisObject对象的类型检查 基于redisObject对象的显式多态函数 对redisObject进行分配、共享和销毁的机制 参考链接：https://redisbook.readthedocs.io/en/latest/datatype/object.html\nredisObject # redisObject 是 Redis 类型系统的核心， 数据库中的每个键、值，以及 Redis 本身处理的参数， 都表示为这种数据类型。\n在redis6.0中，redisObject的应用如下：\n从上图可以看出，redis没中对象都是由redisObject与对应编码的数据结构组合而成，而没中对象类型对应若干编码方式，不同的编码凡事所对应的底层数据结构也不同。\n在redis中，redisObject的结构为：\ntypedef struct redisObject { // 类型 unsigned type:4; // 编码方式 unsigned encoding:4; // LRU - 24位, 记录最末一次访问时间（相对于lru_clock）; 或者 LFU（最少使用的数据：8位频率，16位访问时间） unsigned lru:LRU_BITS; // LRU_BITS: 24 // 引用计数 int refcount; // 指向底层数据结构实例 void *ptr; } robj; type 、 encoding 和 ptr 是最重要的三个属性。\ntype 记录了对象所保存的值的类型，它的值可能是以下常量的其中一个：\n#define REDIS_STRING 0 // 字符串 #define REDIS_LIST 1 // 列表 #define REDIS_SET 2 // 集合 #define REDIS_ZSET 3 // 有序集 #define REDIS_HASH 4 // 哈希表 encoding 记录了对象所保存的值的编码，它的值可能是以下常量的其中一个:\n#define REDIS_ENCODING_RAW 0 // 编码为字符串 #define REDIS_ENCODING_INT 1 // 编码为整数 #define REDIS_ENCODING_HT 2 // 编码为哈希表 #define REDIS_ENCODING_ZIPMAP 3 // 编码为 zipmap #define REDIS_ENCODING_LINKEDLIST 4 // 编码为双端链表 #define REDIS_ENCODING_ZIPLIST 5 // 编码为压缩列表 #define REDIS_ENCODING_INTSET 6 // 编码为整数集合 #define REDIS_ENCODING_SKIPLIST 7 // 编码为跳跃表 ptr 是一个指针，指向实际保存值的数据结构，这个数据结构由 type 属性和 encoding 属性决定。\nlru记录了对象最后一次被命令程序访问的时间。如果服务器开启了maxmemory选项，并且服务器用于回收的算法为volatile-lru或者allkeys-lru，那么当服务器占用的内存数超过了maxmemory选项所设置的上限值时，空转时长较高的那部分键会优先被服务器释放，从而回收内存。\n对象共享 # redis一般会把一些常见的值放到一个共享对象中，这样可使程序避免了重复分配的麻烦，也节约了一些CPU时间。\nredis预分配的值对象如下：\n各种命令的返回值，比如成功时返回的OK，错误时返回的ERROR，命令入队事务时返回的QUEUE，等等 包括0 在内，小于REDIS_SHARED_INTEGERS的所有整数（REDIS_SHARED_INTEGERS的默认值是10000 共享对象只能被字典和双向链表这类能带有指针的数据结构使用。像整数集合和压缩列表这些只能保存字符串、整数等自勉之的内存数据结构\n对象淘汰 # 在redisObject中存在refcount属性，是对象的引用基数，如果显示为 0 则代表此对象是可以回收的。\n每个redisObject结构都带有一个refcount属性，指示这个对象被引用了多少次； 当新创建一个对象时，它的refcount属性被设置为1； 当对一个对象进行共享时，redis将这个对象的refcount加一； 当使用完一个对象后，或者消除对一个对象的引用之后，程序将对象的refcount减一； 当对象的refcount降至0 时，这个RedisObject结构，以及它引用的数据结构的内存都会被释放。 底层数据结构 # 在上文中提到，redis的底层数据结构主要有：SDS 简单动态字符串、QuickList 快表、ZipList 压缩列表、HasTable 哈希表、InSet 整数集、ZSkipList 跳表。\n详细的说明参考：https://pdai.tech/md/db/nosql-redis/db-redis-x-redis-ds.html\n"},{"id":4,"href":"/docs/arithmetic/data/","title":"数据结构","section":"Docs","content":" 数据结构 # 二叉树 # 红黑树 # # 压缩列表(ziplist) # ziplist是一个经过特殊编码的双向链表，它的设计目标是节省内存。它可以存储字符串或者整数。其中整数是按二进制进行编码的，而不是字符串序列。\n它能以O(1)的时间复杂度在列表的两端进行push和pop操作。但是由于每个操作都 u 要对ziplist所使用的内存进行重新分配，所以实际操作的复杂度与ziplist占用的内存大小有关。\n在redis中，有序集合、散列和列表都直接或间接使用了压缩列表。当有序集合或散列的元素个数较少，并且元素都是短字符串时，redis便会使用压缩列表作为底层数据存储。redis的列表使用的快速链表数据结构进行存储，而快速链表就是双向链表与压缩列表的组合。\n总的来说，ziplist有如下特性：\n本质上是一个字节数组 是redis为了节约内存而设计的一种线性结构 可以包含多个元素，每个元素可以是一个字节数组或一个整数 在redis中，压缩列表主要由 5 部分组成：\n属性 类型 长度 用途 zlbytes unit32_t 4字节 记录整个压缩列表占用的内存字节数：在对压缩列表进行内存重分配，或者计算 zlend 的位置时使用。 zltail unit32_t 4字节 记录压缩列表表尾节点距离压缩列表的起始地址有多少字节：通过这个偏移量，程序无需遍历整个压缩列表就可以确定表尾节点的地址。 zllen unit16_t 2字节 记录了压缩列表包含的节点数量，当这个属性的值小于 UINT16_MAX（65535）时，这个属性的值就是压缩列表包含节点的数量；当这个值等于 UINT16_MAX 时，节点的真实数量需要遍历整个压缩列表才能计算得出。 entry 列表节点 不定 压缩列表包含的各个节点 zlend unit8_t 1字节 特殊值 0xFF（十进制 255），用于标记压缩列表的末端。 如上图所示，这是一个包含三个节点的压缩列表的示例：\nzlbytes 属性的值为 0x50（十进制 80），表示压缩列表的总长为 80 字节。 zltail 属性的值为 0x3c（十进制 60），这表示如果我们有一个指向压缩列表起始地址的指针 p，那么只要用指针 p 加上偏移量 60，就可以计算出表尾节点 entry3 的地址。 zllen 属性的值为 0x3（十进制 3），表示压缩列表包含三个节点。 对于压缩列表而言，每个entry的数据结构又包含三部分，分别是：\nprevious_entry_length:表示前一个元素的长度，占 1 字节或者 5 字节 当前一个元素的长度小于 254 字节时，使用 1 字节表示记录上一个元素长度 当前一个元素的长度大于或等于 254 字节时，用 5 字节表示。其中第一个字节固定为0xFE(十进制为 254)，后 4 字节才是上一个元素的真正长度 encoding：当前元素的编码，记录节点的content字段锁保存的数据的类型以及长度，它的类型一共有两种，分别是字节数组和整数。它的长度可能为 1字节、2 字节或者 5 字节 content：用于保存当前节点的内容，节点内容类型和长度由encoding决定 encoding内容说明\n当content要存储的数据是字节数组时:\n内容 长度 描述 00 bbbbbb 1字节 最大长度为 63 的字节数组 01 bbbbbb xxxxxxxx 2字节｜最大长度 2^14-1的字节数组 10 ________ aaaaaaaa bbbbbbbb cccccccc dddddddd 5字节 最大长度2^32-1的字节数组 当content要存储的数据是整数时：\n内容 长度 描述 11000000 1字节 int16_t类型整数(2字节) 11010000 1字节 int32_t类型整数(4字节) 11100000 1字节 int64_t类型整数(8字节) 11110000 1字节 24位有符号整数(3字节) 11111110 1字节 8 位有符号整数(1字节) 1111xxxx 1字节 用xxxx思维表示内容，此时将不在需要content 11111111 1字节 表示压缩列表的结束 跳跃表(zSkiplist) # 跳跃表即跳表，是一个可以快速查询有序连续元素的数据链表。跳表的平均查找和插入时间复杂度都是O(long n)，优于普通队列的O(n)。\n它最大的优势是原理简单、容易实现、方便扩展、效率更高。因此在一些热门的项目中用来替代平衡树，它最典型的用途就是作为redis中的zset的基础数据类型。\n跳表是在链表的基础上，增加了多级索引，通过索引位置的几个跳转，实现数据的快速定位。\n由上图可见，针对存储的数据个数，增加多级索引，查找数据时，按照多级索引，一级一级地以此查找，从而缩短查询的时间，当定位到原始链表后，如果没有查找到对应的值，那么也可以说明这个有序链表中不存在这个元素。\n跳表查询的时间复杂度计算：\nn/2、n/4、n/8、第 k 级索引结点的个数就是 n/(2^k)\n假设索引有 h 级，最高级的索引有 2 个结点。n/(2^h) = 2，从而求得 h = log2(n)-1\n举一个例子，跳表在查询的时候，假设索引的高度：logn，每层索引遍历的结点个数：3，假设要走到第 8 个节点。\n每层要遍历的元素总共是3个，所以这里的话 log2 8 的话，就是它的时间复杂度。最后的话得出证明出来：时间复杂度为log2n。也就是从最朴素的原始链表的话，它的 O(n) 的时间复杂度降到 log2n 的时间复杂度。这已经是一个很大的改进了。假设是1024的话，你会发现原始链表要查1024次最后得到这个元素，那么这里的话就只需要查（2的10次方是1024次）十次这样一个数量级。\n跳表的空间复杂度计算：\n假设它的长度为 n，然后按照之前的例子，每两个节点抽一个做成一个索引的话，那么它的一级索引为二分之 n 对吧。最后如下：\n原始链表大小为 n，每 2 个结点抽 1 个，每层索引的结点数: n/2,n/4,n/8,\u0026hellip;\u0026hellip;,8,4,2\n原始链表大小为 n，每 3 个结点抽 1 个，每层索引的结点数: n/3,n/9,n/27,\u0026hellip;\u0026hellip;,9,3,1\n空间复杂度是 O(n)\n跳表的构成\n从图中可以看到， 跳跃表主要由以下部分构成：\n表头（head）：负责维护跳跃表的节点指针。 跳跃表节点：保存着元素值，以及多个层。 层：保存着指向其他元素的指针。高层的指针越过的元素数量大于等于低层的指针，为了提高查找的效率，程序总是从高层先开始访问，然后随着元素值范围的缩小，慢慢降低层次。 表尾：全部由 NULL 组成，表示跳跃表的末尾。 用java实现跳表 # 参考链接\nimport java.util.concurrent.ThreadLocalRandom; /** * 跳跃表实现 */ public class SkipLists\u0026lt;Key extends Comparable\u0026lt;Key\u0026gt;, Value\u0026gt; { public static final int MAX_LEVEL = 32; private static final Object BASE_OBJECT = new Object(); private static final int PROBABILITY = 50; private volatile HeaderIndex\u0026lt;Key, Value\u0026gt; header; public SkipLists() { this.header = new HeaderIndex(new Node(null, BASE_OBJECT, null), null, null, 1); } /** * 根据key从跳跃表中获取一个值 * @param key key * @return 存在则返回对应的value，不存在则返回null */ public Value get(Key key) { // 参数检查 if (key == null) { throw new IllegalArgumentException(); } // 找到key对应的前驱节点 Node\u0026lt;Key, Value\u0026gt; predecessor = findPredecessor(key); // 从前驱节点开始遍历查找key对应的节点 for (Node\u0026lt;Key, Value\u0026gt; next = predecessor.next;;) { if (next == null) { break; } // key与节点的Key比较 // 如果相等就找到了直接返回值 // 如果key大于节点的key，继续向后查找 // 如果key小于节点的key，那么没找到，退出循环 int cmp = key.compareTo(next.key); if (cmp == 0) { return next.value; } else if (cmp \u0026gt; 0) { next = next.next; } else { break; } } return null; } /** * 向跳跃表添加一个key-value对 * @param key key * @param value value */ public void put(Key key, Value value) { if (key == null) { throw new NullPointerException(); } Node\u0026lt;Key, Value\u0026gt; newNode = null; // 找到最底层插入节点的前驱节点 Node\u0026lt;Key, Value\u0026gt; predecessor = findPredecessor(key); // 找到索引节点对应的数据节点以后，开始查找插入数据前驱节点 for (Node\u0026lt;Key, Value\u0026gt; b = predecessor, next = b.next;;) { if (next != null) { // 如果插入的key大于当前数据节点，那么继续查找下一个 int cmp = key.compareTo(next.key); if (cmp \u0026gt; 0) { b = next; next = next.next; continue; } else if (cmp == 0) { next.value = value; break; } } // 新建节点并更改前驱节点的下一个节点为新节点 newNode = new Node\u0026lt;\u0026gt;(key, value, next); b.next = newNode; break; } // 是否要为数据节点添加索引层 int level = randomLevel(); // 需要加层 if (level \u0026gt; header.level) { int oldLevel = header.level; int newLevel = level; // 为新节点创建索引节点 Index\u0026lt;Key, Value\u0026gt;[] newNodeIndexes = createNewNodeIndex(newNode, newLevel); // 为头结点增量补充索引节点,并将头结点的索引节点指向新节点的索引节点 header = incrHeaderIdxes(newLevel, newNodeIndexes); // 根据老层更新新节点的数据 updateIndex(key, newNodeIndexes[oldLevel], oldLevel, newLevel); } else { // 如果节点索引层大于1就需要为节点新建索引层 if (level \u0026gt; 1) { // 根据新节点索引层新建节点索引 Index\u0026lt;Key, Value\u0026gt;[] newNodeIndexes = createNewNodeIndex(newNode, level); // 更新索引 // 在没有新建层时，为新节点新建层传入的新层参数是头索引的层数，因为每次都从头索引开始查找， // 需要将头索引直接下降到对应的层后开始修改关系 updateIndex(key, newNodeIndexes[level], level, header.level); } } } /** * 根据key删除一个节点 * 注意删除节点可能需要减层 * @param key 要删除的关键字 * @return key对应的value值，如果没有找到value就返回null */ public Value delete(Key key) { if (key == null) { throw new NullPointerException(); } Value val = null; // 找到最底层插入节点的前驱节点 Node\u0026lt;Key, Value\u0026gt; predecessor = findPredecessor(key); for (Node\u0026lt;Key, Value\u0026gt; b = predecessor, next = b.next;;) { if (next != null) { // 如果插入的key大于当前数据节点，那么继续查找下一个 int cmp = key.compareTo(next.key); if (cmp \u0026gt; 0) { b = next; next = next.next; continue; } else if (cmp \u0026lt; 0) { break; } else { // 相等就将节点元素设置为空 val = next.value; next.value = null; break; } } break; } // 通过查找前驱索引节点删除可能需要删除的索引 // 删除索引的标记信息就是node.value==null findPredecessor(key); // 删除层 // 如果头索引的右侧索引已经被删除就减层 while (header.right == null \u0026amp;\u0026amp; header.level \u0026gt; 1) { header = (HeaderIndex\u0026lt;Key, Value\u0026gt;) header.down; } return val; } /** * 查找key对应的前驱索引 * @param key key * @return 前驱索引 */ private Index\u0026lt;Key, Value\u0026gt; findIndex(Key key) { for (Index\u0026lt;Key, Value\u0026gt; cur = header, right = cur.right, down;;) { // 如果索引的右侧不为空 // 用搜索的key对数据节点的key进行比较 // 如果搜索的key大于索引节点的key，那么继续向右进行搜索 if (right != null) { Node\u0026lt;Key, Value\u0026gt; n = right.node; Key k = n.key; // value为空代表节点的值已经被删除 // 删除节点对应的索引 if (n.value == null) { // 将当前所有的右侧索引更新为右侧的右侧 cur.right = right.right; // 更新right索引变量为当前索引的右侧 right = cur.right; continue; } // 如果搜索的key大于右侧节点指向的key，那么继续向右查找 if (key.compareTo(k) \u0026gt; 0) { cur = right; right = right.right; continue; } } // 如果索引节点的右侧节点大于key，那么向下放索引查找 if ((down = cur.down) != null) { // 将当前节点指向下方索引节点 // 右侧节点指针指向下方索引的右侧 cur = down; right = down.right; } else { return cur; } } } /** * 查找key对应的前驱节点 * @param key key * @return 前驱节点 */ private Node\u0026lt;Key, Value\u0026gt; findPredecessor(Key key) { Index\u0026lt;Key, Value\u0026gt; index = findIndex(key); return index.node; } /** * 更新老层的索引 * @param key 关键字 * @param newNodeOldIdx 新节点索引 * @param oldLevel 老层数 * @param newLevel 新层数 */ private void updateIndex(Key key, Index\u0026lt;Key, Value\u0026gt; newNodeOldIdx, int oldLevel, int newLevel) { Index\u0026lt;Key, Value\u0026gt; newNodeIdx = newNodeOldIdx; Index\u0026lt;Key, Value\u0026gt; precursorIdx = header; // 跳过新索引层，因为已经做了关联 for (int i = oldLevel + 1; i \u0026lt;= newLevel; i++) { precursorIdx = precursorIdx.down; } Index\u0026lt;Key, Value\u0026gt; right = precursorIdx.right; // 找到对应的层之后，我们开始向右继续查找前驱索引节点 while (true) { if (right != null \u0026amp;\u0026amp; right.node.value != null) { int cmp = key.compareTo(right.node.key); if (cmp \u0026gt; 0) { precursorIdx = right; right = right.right; continue; } } // 找到需要更新的索引之后，重建索引 // 前驱索引节点的右侧设置新的索引 precursorIdx.right = newNodeIdx; // 新索引有右侧设置为老索引的右侧节点 newNodeIdx.right = right; // 新节点索引向下 newNodeIdx = newNodeIdx.down; // 老索引向下 precursorIdx = precursorIdx.down; if (precursorIdx == null) { break; } } } /** * 随机生成节点的层，但是不超过32 * @return 新节点层数 */ private int randomLevel() { int level = 1; int rnd = ThreadLocalRandom.current().nextInt(1, 101); while (rnd \u0026gt; PROBABILITY \u0026amp;\u0026amp; level \u0026lt;= MAX_LEVEL) { // 根据随机数来生成索引层数 ++level; rnd = ThreadLocalRandom.current().nextInt(1, 101); } return level; } /** * 为头结点补充索引层级 * @param newLevel 新层数 * @param newNodeIdxes 新节点索引数组 * @return 新的头结点 */ private HeaderIndex\u0026lt;Key, Value\u0026gt; incrHeaderIdxes(int newLevel, Index\u0026lt;Key, Value\u0026gt;[] newNodeIdxes) { HeaderIndex\u0026lt;Key, Value\u0026gt; newHeader = header; for (int i = header.level + 1; i \u0026lt;= newLevel; i++) { newHeader = new HeaderIndex\u0026lt;\u0026gt;(header.node, newHeader, newNodeIdxes[i], i); } return newHeader; } /** * 为新节点创建索引节点，并建立向下的索引关系 * @param newNode 新节点 * @param newLevel 层数 * @return 新节点的索引节点 */ private Index\u0026lt;Key,Value\u0026gt;[] createNewNodeIndex(Node\u0026lt;Key,Value\u0026gt; newNode, int newLevel) { Index\u0026lt;Key,Value\u0026gt;[] newNodeIdxes = new Index[newLevel + 1]; Index\u0026lt;Key,Value\u0026gt; newIndex = null; for (int i = 1; i \u0026lt;= newLevel; i++) { newIndex = new Index\u0026lt;\u0026gt;(newNode, newIndex, null); newNodeIdxes[i] = newIndex; } return newNodeIdxes; } /** * 数据节点 */ static class Node\u0026lt;Key, Value\u0026gt; { /** * 键 */ final Key key; /** * 值 */ volatile Value value; /** * 链表指针 */ volatile Node\u0026lt;Key, Value\u0026gt; next; public Node(Key key, Value value, Node\u0026lt;Key, Value\u0026gt; next) { this.key = key; this.value = value; this.next = next; } } /** * 索引 */ static class Index\u0026lt;K,V\u0026gt; { final Node\u0026lt;K,V\u0026gt; node; volatile Index\u0026lt;K,V\u0026gt; right; volatile Index\u0026lt;K,V\u0026gt; down; public Index(Node\u0026lt;K,V\u0026gt; node, Index\u0026lt;K,V\u0026gt; down, Index\u0026lt;K,V\u0026gt; right) { this.node = node; this.right = right; this.down = down; } } /** * 头 */ static class HeaderIndex\u0026lt;K,V\u0026gt; extends Index\u0026lt;K,V\u0026gt; { private final int level; public HeaderIndex(Node\u0026lt;K,V\u0026gt; node, Index\u0026lt;K,V\u0026gt; down, Index\u0026lt;K,V\u0026gt; right, int level) { super(node, down, right); this.level = level; } } } redis跳表的实现 # Redis 的跳跃表由 redis.h/zskiplistNode 和 redis.h/zskiplist 两个结构定义， 其中 zskiplistNode 结构用于表示跳跃表节点， 而 zskiplist 结构则用于保存跳跃表节点的相关信息， 比如节点的数量， 以及指向表头节点和表尾节点的指针， 等等。\n上图展示了一个跳跃表示例，位于图片最左边的示 zskiplist 结构，该结构包含以下属性：\nheader ：指向跳跃表的表头节点。 tail ：指向跳跃表的表尾节点。 level ：记录目前跳跃表内，层数最大的那个节点的层数（表头节点的层数不计算在内）。 length ：记录跳跃表的长度，也即是，跳跃表目前包含节点的数量（表头节点不计算在内）。 位于 zskiplist 结构右方的是四个 zskiplistNode 结构， 该结构包含以下属性：\n层（level）：节点中用 L1 、 L2 、 L3 等字样标记节点的各个层， L1 代表第一层， L2 代表第二层，以此类推。每个层都带有两个属性：前进指针和跨度。前进指针用于访问位于表尾方向的其他节点，而跨度则记录了前进指针所指向节点和当前节点的距离。在上面的图片中，连线上带有数字的箭头就代表前进指针，而那个数字就是跨度。当程序从表头向表尾进行遍历时，访问会沿着层的前进指针进行。 后退（backward）指针：节点中用 BW 字样标记节点的后退指针，它指向位于当前节点的前一个节点。后退指针在程序从表尾向表头遍历时使用。 分值（score）：各个节点中的 1.0 、 2.0 和 3.0 是节点所保存的分值。在跳跃表中，节点按各自所保存的分值从小到大排列。 成员对象（obj）：各个节点中的 o1 、 o2 和 o3 是节点所保存的成员对象。 参考链接：https://juejin.cn/post/6893072817206591496\n"},{"id":5,"href":"/docs/database/redis/high/","title":"Redis高可用","section":"Redis","content":" 高可用 # 主从复制 # TODO\n哨兵模式 # TODO\n分片技术 # TODO\n"},{"id":6,"href":"/docs/database/redis/apply/","title":"Redis应用实践","section":"Redis","content":" 应用实践 # 缓存场景问题 # 常见的redis问题主要有：\n缓存和数据库双写一致性问题 缓存雪崩问题 缓存击穿问题 缓存穿透问题 缓存的并发竞争问题 双写一致性如何保证 # 什么一致性 # 首先是一致性问题，在分布式系统中，可以理解为多个节点中数据的值是一致的。\n强一致性：这种一致性级别是最符合用户直觉的，它要求系统写入什么，读出来的也会是什么，用户体验好，但实现起来往往对系统的性能影响大 弱一致性：这种一致性级别约束了系统在写入成功后，不承诺立即可以读到写入的值，也不承诺多久之后数据能够达到一致，但会尽可能地保证到某个时间级别（比如秒级别）后，数据能够达到一致状态 最终一致性：最终一致性是弱一致性的一个特例，系统会保证在一定时间内，能够达到一个数据一致的状态。这里之所以将最终一致性单独提出来，是因为它是弱一致性中非常推崇的一种一致性模型，也是业界在大型分布式系统的数据一致性上比较推崇的模型 三个经典缓存模式 # 缓存可以提升性能、缓解数据库压力，但是使用缓存也会导致数据不一致性的问题。一般使用缓存的方式有三种：\nCache-Aside Pattern，旁路缓存模式，主要特点为： 读的时候，先读缓存，缓存命中的话，直接返回数据 缓存没有命中的话，就去读数据库，从数据库取出数据，放入缓存后，同时返回响应。 更新时先更新数据库，然后再删除缓存 Read-Through/Write through，读写穿透模式，服务端把缓存作为主要数据存储。应用程序跟数据库缓存交互，都是通过抽象缓存层完成的。 从缓存读取数据，读到直接返回 如果读取不到的话，从数据库加载，写入缓存后，再返回响应。 与Cache-Aside相似，仅是在它之上增加了一个抽象层 Write behind，异步缓存写入模式 与Read-Through/Write-Through类似，都有一个抽象层负责缓存和数据库的读写 不同的是，Write Behind只负责更新缓存，不直接对数据库进行操作，他通过异步的批量操作的方式去更新数据库 这种方式下，缓存和数据库的一致性不强，对一致性要求高的系统要谨慎使用 适合频繁写的场景，MySQL的InnoDB Buffer Pool机制就使用到这种模式。 缓存数据更新 # 在操作缓存的时候，是应该去更新缓存，还是删除后重建？\n一般情况下，我们是删除缓存，再下次读取时，获取到数据库数据后再新建缓存数据。\n对于这两种的选择的情况一般如下\n删除缓存的场景：\n写入场景较多（当然写的场景较多的情况下，也需要考虑是否需要引入缓存） 缓存计算逻辑复杂 更新缓存的场景：\n写数据库较少 更新频率低 双写情况下，是先操作数据库还是缓存 # Cache-Aside缓存模式中，在写入请求的时候，为什么是先操作数据库呢？为什么不先操作缓存呢？\n由于使用的是删除缓存的方式，如果是先操作缓存再操作数据库，此时两个线程并发读写，就会可能出现缓存中的数据与数据库数据不一致的问题。\n保证一致性的一些方法 # 同事务强一致性 # 对于非分布式系统而言，我们可以使数据库操作与redis操作在同一个事务中，具体流程是：\n开启事务 修改数据库 执行redis命令 提交事务 基于这种方式，可以保证数据库被修改，缓存一定被删除，但这种方式局限较多。\n缓存延时双删 # 什么是延时双删：\n写请求-\u0026gt;删除缓存-\u0026gt;更新数据-\u0026gt;休眠一会-\u0026gt;删除缓存\n休眠时间一般为：读业务逻辑数据的耗时 + 几百毫秒\n为了确保读请求结束，写请求可以删除读请求可能带来的缓存脏数据。\n删除缓存重试机制 # 对于延时双删、Cache-Aside的先操作数据库再删除缓存都会存在一个问题：在删除缓存时失败了，导致数据库与缓存不一致\n为了解决这一个问题，我们可以引入一个失败重试机制，引入消息队列，当第一次删除缓存失败后，将要删除的key加入消息队列中，后续由消息队列消费者执行删除逻辑，直到删除成功。\n为保证一致性，这里再添加消息队列的时候，应该使用事务消息，保证消息队列添加与数据库修改在同一个事务中，以此可以进一步保证一致性。\n当然，对于消息队列而言，应存在一个失败次数限制，当失败次数达到时，应该通知管理员介入进行处理。\n通过binlog异步删除缓存 # 对于 MySQL 而言，可以通过数据库的binlog来异步淘汰key。具体的可以使用阿里的canal将binlog日志采集发送到MQ队列里面，然后通过ACK机制确认处理这条更新消息，删除缓存，保证数据缓存一致性。\n当然对于其他数据库也有其他相应的插件。\n缓存雪崩 # 什么是缓存雪崩 # 造成缓存雪崩的主要原因有二：\n大量缓存数据同时过期 redis故障 通常我们为了保证缓存中的数据与数据库中的数据一致性，会给 Redis 里的数据设置过期时间，当缓存数据过期后，用户访问的数据如果不在缓存里，业务系统需要重新生成缓存，因此就会访问数据库，并将数据更新到 Redis 里，这样后续请求都可以直接命中缓存。\n当大量缓存数据在同一时间过期（失效）或者 Redis 故障宕机时，如果此时有大量的用户请求，都无法在 Redis 中处理，于是全部请求都直接访问数据库，从而导致数据库的压力骤增，严重的会造成数据库宕机，从而形成一系列连锁反应，造成整个系统崩溃，这就是缓存雪崩的问题。\n针对大量缓存数据同时过期的应对措施是：\n均匀设置过期时间：给这些数据的过期时间加上一个随机数，这样就保证数据不会在同一时间过期。 增加互斥锁 如果发现访问的数据不在 Redis 里，就加个互斥锁，保证同一时间内只有一个请求来构建缓存（从数据库读取数据，再将数据更新到 Redis 里），当缓存构建完成后，再释放锁 未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值 实现互斥锁时应该增加一个超时时间，避免程序一直处于阻塞状态 后台更新缓存：业务线程不再负责更新缓存，缓存也不设置有效期，而是让缓存“永久有效”，并将更新缓存的工作交由后台线程定时更新 对于后台更新缓存而言，也存在极大的弊端，当系统内存紧张的时候，有些缓存数据会被“淘汰”，而在缓存被“淘汰”到下一次后台定时更新缓存的这段时间内，业务线程读取缓存失败就返回空值，业务的视角就以为是数据丢失了。\n为解决这一弊端的方法有两个：\n后台线程不仅负责定时更新缓存，而且也负责频繁地检测缓存是否有效，检测到缓存失效了，原因可能是系统紧张而被淘汰的，于是就要马上从数据库读取数据，并更新到缓存。这种方式也存在弊端，那就是检测时间间隔不能太长，太长也导致用户获取的数据是一个空值而不是真正的数据 通过消息队列发送一条消息通知后台线程更新缓存，后台线程收到消息后，在更新缓存前可以判断缓存是否存在，存在就不执行更新缓存操作；不存在就读取数据库数据，并将数据加载到缓存。这种方式相比第一种方式缓存的更新会更及时，用户体验也比较好。 针对redis故障的常用的解决方法是：\n服务熔断或请求限流机制 构建 Redis 缓存高可靠集群 服务熔断或请求限流机制： 暂停业务应用对缓存服务的访问，直接返回错误，使得业务线程不在继续访问数据库，从而保障数据库的正常运行。但是直接粗暴处理，会使得业务功能受限，在此可以增加限流机制，只将少部分请求发送到数据库进行处理，再多的请求就在入口直接拒绝服务，等到 Redis 恢复正常并把缓存预热完后，再解除请求限流的机制。\n构建 Redis 缓存高可靠集群： 主从节点的方式构建 Redis 缓存高可靠集群。集群构建参考：redis主从复制\n缓存击穿 # 缓存击穿主要是热点缓存数据过期。对于一个业务系统通常会有一些数据被频繁访问，对于访问频次高的数据称为热点数据。\n在一个系统中，如果缓存中的某个热点数据过期了，此时大量的请求访问到该热点数据，就会出现缓存无法提供，所有的请求都直接访问数据库，从而数据库被高并发的请求冲垮，此类问题就被称为缓存击穿问题。\n稍稍细心一点，不难发现，缓存击穿与缓存雪崩类似，我们可以将缓存击穿认为是缓存雪崩的一个子集。\n所以对于缓存击穿，可以使用缓存雪崩的两种方式去解决：\n增加互斥锁 后台更新缓存数据 缓存穿透 # 当发生缓存雪崩或击穿时，数据库中还是保存了应用要访问的数据，一旦缓存恢复相对应的数据，就可以减轻数据库的压力，而缓存穿透就不一样了。\n缓存穿透是数据既不在缓存也不在数据库\n当用户访问的数据，既不在缓存中，也不在数据库中，导致请求在访问缓存时，发现缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据，没办法构建缓存数据，来服务后续的请求。那么当有大量这样的请求到来时，数据库的压力骤增，这就是缓存穿透的问题。\n缓存穿透的发生一般有这两种情况：\n业务误操作，缓存中的数据和数据库中的数据都被误删除了，所以导致缓存和数据库中都没有数据； 黑客恶意攻击，故意大量访问某些读取不存在数据的业务； 应对缓存穿透的方案，常见的方案有三种:\n非法请求的限制:当有大量恶意请求访问不存在的数据的时候，也会发生缓存穿透，因此在 API 入口处我们要判断求请求参数是否合理，请求参数是否含有非法值、请求字段是否存在，如果判断出是恶意请求就直接返回错误，避免进一步访问缓存和数据库。 增加缓存空值或者默认值：针对查询的数据，在缓存中设置一个空值或者默认值，这样后续请求就可以从缓存中读取到空值或者默认值，返回给应用，而不会继续查询数据库。 使用布隆过滤器进行判断：在写入数据库数据时，使用布隆过滤器做个标记，然后在用户请求到来时，业务线程确认缓存失效后，可以通过查询布隆过滤器快速判断数据是否存在，如果不存在，就不用通过查询数据库来判断数据是否存在。即使发生了缓存穿透，大量请求只会查询 Redis 和布隆过滤器，而不会查询数据库，保证了数据库能正常运行，Redis 自身也是支持布隆过滤器的。 缓存的并发竞争 # 缓存的并发竞争指的是多个客户端同时操作同一个key的值，同时进行set操作所引发的并发问题。\n解决这一问题的方法也简单，只需要添加一个分布式锁即可，对于redis我们可以直接使用redis的setnx实现分布式锁，具体逻辑为：\n业务逻辑处理 for 1 ... 5 { 限制最多重试 5 次 获取分布式锁 if 锁获取成功 { 操作缓存 处理业务逻辑 break } 获取锁失败，休眠一下继续重试 } 如果重试获取锁失败，需要增加失败的逻辑逻辑 对于并发较大的分布式系统，我们还可以使用分消息队列来处理这类问题，利用消息队列的顺序消息功能，将对同一个 key 的操作顺序化\n布隆过滤器 # 布隆过滤器由「初始值都为 0 的位图数组」和「 N 个哈希函数」两部分组成。当我们在写入数据库数据时，在布隆过滤器里做个标记，这样下次查询数据是否在数据库时，只需要查询布隆过滤器，如果查询到数据没有被标记，说明不在数据库中。\n布隆过滤器会通过 3 个操作完成标记：\n使用 N 个哈希函数分别对数据做哈希计算，得到 N 个哈希值； 将第一步得到的 N 个哈希值对位图数组的长度取模，得到每个哈希值在位图数组的对应位置。 将每个哈希值在位图数组的对应位置的值设置为 1； 举个例子，假设有一个位图数组长度为 8，哈希函数 3 个的布隆过滤器。\n在数据库写入数据 x 后，把数据 x 标记在布隆过滤器时，数据 x 会被 3 个哈希函数分别计算出 3 个哈希值，然后在对这 3 个哈希值对 8 取模，假设取模的结果为 1、4、6，然后把位图数组的第 1、4、6 位置的值设置为 1。当应用要查询数据 x 是否数据库时，通过布隆过滤器只要查到位图数组的第 1、4、6 位置的值是否全为 1，只要有一个为 0，就认为数据 x 不在数据库中。\n布隆过滤器由于是基于哈希函数实现查找的，高效查找的同时存在哈希冲突的可能性，比如数据 x 和数据 y 可能都落在第 1、4、6 位置，而事实上，可能数据库中并不存在数据 y，存在误判的情况。\n所以，查询布隆过滤器说数据存在，并不一定证明数据库中存在这个数据，但是查询到数据不存在，数据库中一定就不存在这个数据\n在redis中可以使用bitmaps实现布隆过滤器，通过setbit key offset value(设置值)、getbit key offset(获取值)、bitcount key [start end](获取位图指定范围值为1的个数)命令可以完成对数据的存储。\nRedisson实现布隆过滤器 # 在java应用中，可以通过引入Redisson框架很容易的实现布隆过滤器功能，代码如下：\nimport org.redisson.Redisson; import org.redisson.api.RBloomFilter; import org.redisson.api.RedissonClient; import org.redisson.config.Config; public class RedissonBloomFilter { public static void main(String[] args) { Config config = new Config(); config.useSingleServer().setAddress(\u0026#34;redis://127.0.0.1:6379\u0026#34;); config.useSingleServer().setPassword(\u0026#34;123\u0026#34;); //构造Redisson RedissonClient redisson = Redisson.create(config); RBloomFilter\u0026lt;String\u0026gt; bloomFilter = redisson.getBloomFilter(\u0026#34;phoneList\u0026#34;); //初始化布隆过滤器：预计元素为100000000L,误差率为3% bloomFilter.tryInit(100000000L,0.03); //将号码10086插入到布隆过滤器中 bloomFilter.add(\u0026#34;10086\u0026#34;); //判断下面号码是否在布隆过滤器中 System.out.println(bloomFilter.contains(\u0026#34;123456\u0026#34;));//false System.out.println(bloomFilter.contains(\u0026#34;10086\u0026#34;));//true } } guava实现布隆过滤器 # import com.google.common.base.Charsets; import com.google.common.hash.BloomFilter; import com.google.common.hash.Funnel; import com.google.common.hash.Funnels; public class GuavaBloomFilter { public static void main(String[] args) { BloomFilter\u0026lt;String\u0026gt; bloomFilter = BloomFilter.create(Funnels.stringFunnel(Charsets.UTF_8),100000,0.01); bloomFilter.put(\u0026#34;10086\u0026#34;); System.out.println(bloomFilter.mightContain(\u0026#34;123456\u0026#34;)); System.out.println(bloomFilter.mightContain(\u0026#34;10086\u0026#34;)); } } redis 布隆过滤器插件 # redis官方基于bitmaps数据结构实现了布隆过滤器，并提供了官方插件，下载地址为：https://github.com/RedisLabsModules/rebloom（推荐使用redis 6.x+集成）\n安装步骤如下：\n# 下载插件 wget https://github.com/RedisLabsModules/rebloom/archive/v2.2.6.tar.gz # 解压 tar -zxvf v2.2.6.tar.gz # 编译插件 cd RedisBloom-2.2.6/ 编译完成后会得到一个redisbloom.so文件，修改redis.conf将这个文件加入到配置文件中\nloadmodule /usr/local/soft/RedisBloom-2.2.6/redisbloom.so 最后重启redis即完成插件安装。\n插件安装完成后，redis的命令将会得到扩展：\nbf.add 添加一个元素 bf.exists 判断一个元素是否存在 bf.madd 添加多个元素 bf.mexists 判断多个元素是否存在 详细的说明参考：https://redis.io/docs/data-types/probabilistic/bloom-filter/\n如果不想自己安装，也可以使用官方提供的镜像：\ndocker run -p 6379:6379 -it --rm redis/redis-stack-server:latest 性能调优 # TODO\nspring 集成 # TODO\n"},{"id":7,"href":"/docs/database/redis/base/","title":"Redis基础概念","section":"Redis","content":" Redis基础概念 # Redis是一款内存高速缓存数据库。Redis全称为：Remote Dictionary Server（远程数据服务），使用C语言编写，Redis是一个key-value存储系统（键值存储系统），支持丰富的数据类型，如：String、list、set、zset、hash。Redis是一种支持key-value等多种数据结构的存储系统。可用于缓存，事件发布或订阅，高速队列等场景。支持网络，提供字符串，哈希，列表，队列，集合结构直接存取，基于内存，可持久化。\n为什么要使用redis # 使用redis主要基于其性能与并发的特点。\n比如一个执行耗时久并且结果变动不频繁的SQL，可以尝试将结果放到缓存中，使得请求可以快速响应。\n再比如一个并发很大的功能，如果每次都从数据库获取数据，由于数据库响应问题，可能会出现连接异常，照成响应失败，这时可以将数据放在redis种，提高响应速度，降低数据库压力。\n当然，redis除了性能与并发，也存在其他特点，现将这些特点总结如下：\n读写性能优异：Redis能读的速度是110000次/s,写的速度是81000次/s 数据类型丰富：Redis支持二进制案例的 Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作 原子性：Redis的所有操作都是原子性的，同时Redis还支持对几个操作全并后的原子性执行 发布订阅：Redis支持发布/订阅模式 持久化：Redis支持RDB, AOF等持久化方式 支持分布式部署 redis为什么响应快 # redis响应快的主要因素有：\nredis是基于内存的，读写都在内存中进行 redis是单线程的，不存在上下文切换线程 redis采用多路复用IO,可以处理并发连接 非阻塞IO内部实现采用epoll，采用了epoll+自己实现的简单的事件框架。epoll中的读、写、关闭、连接都转化成了事件，然后利用epoll的多路复用特性，绝不在io上浪费一点时间。 数据结构优化，redis为key-value的存储，使用hash结构，读写速度快；对于特殊的数据类型也引入了特殊的数据结构进行优化，比如使用跳表加快有序的数据结构(比如zset)的读取速度 redis为什么是单线程 # 因为Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了。\n不需要各种锁的性能消耗 redis的数据结构并不全是简单的Key-Value，还有list，hash等复杂的结构，这些结构有可能会进行很细粒度的操作，比如在很长的列表后面添加一个元素，在hash当中添加或者删除 一个对象。这些操作可能就需要加非常多的锁，导致的结果是同步开销大大增加。\n总之，在单线程的情况下，就不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗。\n单线程多进程集群方案 单线程的威力实际上非常强大，每核心效率也非常高，多线程自然是可以比单线程有更高的性能上限，但是在今天的计算环境中，即使是单机多线程的上限也往往不能满足需要了，需要进一步摸索的是多服务器集群化的方案，这些方案中多线程的技术照样是用不上的。\n所以单线程、多进程的集群不失为一个时髦的解决方案。\nCPU消耗 采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU。但是如果CPU成为Redis瓶颈，或者不想让服务器其他CUP核闲置，那怎么办?可以考虑多起几个Redis进程，Redis是key-value数据库，不是关系数据库，数据之间没有约束。只要客户端分清哪些key放在哪个Redis进程上就可以了。\n什么是多路复用 IO # Redis单线程的优劣势单进程单线程优势代码更清晰，处理逻辑更简单不用去考虑各种锁的问题，不存在加锁释放锁操作，不会因为可能出现死锁而导致的性能消耗，不存在多进程或者多线程导致的切换而消耗CPU\n不过在单线程下无法发挥多核CPU性能，于是redis引入多路复用 IO 方案来保证多连接时的系统吞吐量。\n其中：\n多路：指的是多个socket连接，即多个网络连接 复用：指的是复用一个线程 多路复用主要有三种技术：select，poll，epoll。redi采用的是epoll。\n采用多路 IO 复用技术可以让单个线程高效的处理多个连接请求(尽量减少网络IO的时间消耗)，且Redis在内存中操作数据的速度非常快(内存内的操作不会成为这里的性能瓶颈)，主要以上两点造就了Redis具有很高的吞吐量。\n在redis中，所有的接收到的请求，都会由单线程来处理（多路复用 IO），而这个单线程并不会立即处理，而是所有的命令都会进入一个 Socket 队列中，当 socket 可读则交给单线程事件分发器逐个被执行。\nredis 6.0 中的多线程 # 随着硬件性能提升，Redis 的性能瓶颈可能出现网络 IO 的读写，也就是：单个线程处理网络读写的速度跟不上底层网络硬件的速度。\n读写网络的read/write系统调用占用了Redis 执行期间大部分 CPU 时间，瓶颈主要在于网络的 IO 消耗, 优化主要有两个方向:\n提高网络 IO 性能，典型的实现比如使用 DPDK 来替代内核网络栈的方式。 使用多线程充分利用多核，提高网络请求读写的并行度，典型的实现比如 Memcached 在redis中采用的办法是使用多个 IO 线程处理网络请求，提高网络请求处理的并行度。需要注意的是，Redis 多 IO 线程模型只用来处理网络读写请求，对于 Redis 的读写命令，依然是单线程处理。\n主要流程：\n主线程负责接收建立连接请求，获取 socket 放入全局等待读处理队列； 主线程通过轮询将可读 socket 分配给 IO 线程； 主线程阻塞等待 IO 线程读取 socket 完成； 主线程执行 IO 线程读取和解析出来的 Redis 请求命令； 主线程阻塞等待 IO 线程将指令执行结果回写回 socket完毕； 主线程清空全局队列，等待客户端后续的请求。 在redis 6.0中，IO 多线程默认是关闭的，如需开启需要修改 redis.conf 配置文件：io-threads-do-reads yes,同时也需要执行线程数，否儿将不生效：io-threads 4\n对于线程数的设置，官方有一个建议：4 核的机器建议设置为 2 或 3 个线程，8核的建议设置为 6 个线程，线程数一定要小于机器核数。\n线程数并不是越大越好，官方认为超过了 8 个基本就没什么意义了。\nredis使用场景 # 热点数据缓存 # 缓存是Redis最常见的应用场景，之所有这么使用，主要是因为Redis读写性能优异。而且逐渐有取代memcached，成为首选服务端缓存的组件。而且，Redis内部是支持事务的，在使用时候能有效保证数据的一致性。\n作为缓存使用时，一般有两种方式保存数据：\n读取前，先去读Redis，如果没有数据，读取数据库，将数据拉入Redis。 插入数据时，同时写入Redis。 方案一：实施起来简单，但是有两个需要注意的地方：\n避免缓存击穿。（数据库没有就需要命中的数据，导致Redis一直没有数据，而一直命中数据库。） 数据的实时性相对会差一点。 方案二：数据实时性强，但是开发时不便于统一处理。\n两种方式根据实际情况来适用。如：方案一适用于对于数据实时性要求不是特别高的场景。方案二适用于字典表、数据量不大的数据存储。\n当然除了这两个方案，对于数据变化不大，但又强调响应速度的场景，可以预先将数据写入缓存，然后应用程序仅读取redis，然后仅在需要变更的时候，再对redis进行修改。\n限时业务的运用 # redis中可以使用expire命令设置一个键的生存时间，到时间后redis会删除它。利用这一特性可以运用在限时的优惠活动信息、手机验证码等业务场景。\n延时处理 # 比如在订单生产后我们占用了库存，10分钟后去检验用户是否真正购买，如果没有购买将该单据设置无效，同时还原库存。 由于redis自2.8.0之后版本提供Keyspace Notifications功能，允许客户订阅Pub/Sub频道，以便以某种方式接收影响Redis数据集的事件。 所以我们对于上面的需求就可以用以下解决方案，我们在订单生产时，设置一个key，同时设置10分钟后过期， 我们在后台实现一个监听器，监听key的实效，监听到key失效时将后续逻辑加上。当然我们也可以利用rabbitmq、activemq等消息中间件的延迟队列服务实现该需求。#\n计数器 # redis由于incrby命令可以实现原子性的递增，所以可以运用于高并发的秒杀活动、分布式序列号的生成、具体业务还体现在比如限制一个手机号发多少条短信、一个接口一分钟限制多少请求、一个接口一天限制调用多少次等等。\n排行榜 # 关系型数据库在排行榜方面查询速度普遍偏慢，所以可以借助redis的SortedSet进行热点数据的排序。\n比如点赞排行榜，做一个SortedSet, 然后以用户的openid作为上面的username, 以用户的点赞数作为上面的score, 然后针对每个用户做一个hash, 通过zrangebyscore就可以按照点赞数获取排行榜，然后再根据username获取用户的hash信息，这个当时在实际运用中性能体验也蛮不错的。\n点赞、好友等关系存储 # Redis 利用集合的一些命令，比如求交集、并集、差集等。\n在微博应用中，每个用户关注的人存在一个集合中，就很容易实现求两个人的共同好友功能。\n分布式锁 # 这个主要利用redis的setnx命令进行，setnx：\u0026ldquo;set if not exists\u0026quot;就是如果不存在则成功设置缓存同时返回1，否则返回0 ，这个特性在很多后台中都有所运用，因为我们服务器是集群的，定时任务可能在两台机器上都会运行，所以在定时任务中首先 通过setnx设置一个lock， 如果成功设置则执行，如果没有成功设置，则表明该定时任务已执行。\n当然结合具体业务，我们可以给这个lock加一个过期时间，比如说30分钟执行一次的定时任务，那么这个过期时间设置为小于30分钟的一个时间就可以，这个与定时任务的周期以及定时任务执行消耗时间相关。\n在分布式锁的场景中，主要用在比如秒杀系统等。\nredis版本特性 # TODO\nredis4.0 # redis5.0 # redis6.0 # redis7.0 # "},{"id":8,"href":"/docs/database/mysql/cluster/","title":"集群","section":"MySQL","content":" 集群配置 # 主从同步 # MySQL 官方提供的同步方案，用于将一个 MySQL 的实例同步到另一个实例中。Replication 为保证数据安全做了重要的保证，是目前运用最广的 MySQL 容灾方案。Replication 用两个或以上的实例搭建了 MySQL 主从复制集群，提供单点写入，多点读取的服务，实现了读的scale out。\n主从介绍 # 实现原理：\n在主从复制中，从库利用主库上的 binlog 进行重播，实现主从同步，复制的过程中蛀主要使用到了 dump thread，I/O thread，sql thread 这三个线程：\nIO thread: 在从库执行 start slave 语句时创建，负责连接主库，请求 binlog，接收 binlog 并写入 relay-log； dump thread：用于主库同步 binlog 给从库，负责响应从 IO thread 的请求。主库会给每个从库的连接创建一个 dump thread，然后同步 binlog 给从库； sql thread：读取 relay log 执行命令实现从库数据的更新。 主从同步优点：\n通过读写分离实现横向扩展的能力，写入和更新操作在源服务器上进行，从服务器中进行数据的读取操作，通过增大从服务器的个数，能够极大的增强数据库的读取能力； 数据安全，因为副本可以暂停复制过程，所以可以在副本上运行备份服务而不会破坏相应的源数据； 方便进行数据分析，可以在写库中创建实时数据，数据的分析操作在从库中进行，不会影响到源数据库的性能； 配置主从同步 # 编写启动主从集群需要的配置文件：\ndocker-compose.yml\nversion: \u0026#39;3\u0026#39; services: mysql-master: restart: always environment: - MYSQL_ROOT_PASSWORD=root image: \u0026#34;mysql:8.0\u0026#34; volumes: - ./master.cnf:/etc/mysql/my.cnf ports: - \u0026#34;10301:3306\u0026#34; mysql-slave: restart: always image: \u0026#34;mysql:8.0\u0026#34; environment: - MYSQL_ROOT_PASSWORD=root volumes: - ./slave.cnf:/etc/mysql/my.cnf ports: - \u0026#34;10302:3306\u0026#34; master.cnf\n[mysqld] server-id=10 # 开启 binlog log_bin=master-bin log_bin-index=master-bin.index # 允许最大连接数 max_connections=200 # 允许连接失败的次数 max_connect_errors=10 # 服务端使用的字符集默认为UTF8 character-set-server=utf8 # 创建新表时将使用的默认存储引擎 default-storage-engine=INNODB slave.cnf\n[mysqld] # 主库和从库需要不一致 server-id=11 # 打开MySQL中继日志 relay-log-index=slave-relay-bin.index relay-log=slave-relay-bin # 打开从服务二进制日志 log-bin=mysql-bin # 使得更新的数据写进二进制日志中 log-slave-updates=1 # 允许最大连接数 max_connections=200 # 允许连接失败的次数 max_connect_errors=10 # 服务端使用的字符集默认为UTF8 character-set-server=utf8 # 创建新表时将使用的默认存储引擎 default-storage-engine=INNODB 拉起服务后，进入主节点容器，创建用于同步的账号：\nCREATE USER \u0026#39;slave\u0026#39;@\u0026#39;%\u0026#39; IDENTIFIED BY \u0026#39;password\u0026#39;; GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO \u0026#39;slave\u0026#39;@\u0026#39;%\u0026#39;; 查看主节点状态：\nshow master status; 进入从节点容器，执行命令，链接主节点:\nCHANGE MASTER TO master_host = \u0026#39;mysql-master\u0026#39;, master_user = \u0026#39;slave\u0026#39;, master_password = \u0026#39;password\u0026#39;, master_port = 3306, master_log_file = \u0026#39;master-bin.000003\u0026#39;, master_log_pos = 712, master_connect_retry = 30; 注意:\nmaster_host为docker容器的名称，如果不是使用的docker部署，需要改为实际的主节点ip。 master_log_file与master_log_pos的值来源于show master status的执行结果。 启动主从同步：start salve （对应的停止同步为stop salve）。\n查看从节点状态：\nshow slave status \\G; 打印如下则代表启动成功（启动失败时，会打印响应的错如日志，根据日志进行解决即可）：\nSlave_IO_Running: Yes Slave_SQL_Running: Yes 测试主从同步，在主节点执行命令：\ncreate database testdb; use testdb; create table t_user(id int,name varchar(200),primary key(id)); insert into t_user (1,\u0026#39;name\u0026#39;); 在从节点执行查询sql:\nselect * from t_user; 执行结果如下，证明主从同步配置成功：\n+----+------+ | id | name | +----+------+ | 1 | name | +----+------+ 1 row in set (0.00 sec) springboot 配置mysql主从集群 # 源码参考：https://github.com/jiangliuhong/olcp/blob/master/olcp-common/olcp-common-db/src/main/java/top/jiangliuhong/olcp/common/DatasourceClusterConfig.java\n定义动态切换的数据源\npublic class RoutingDataSource extends AbstractRoutingDataSource { @Override protected Object determineCurrentLookupKey() { return ClusterDBContext.get(); } } 创建集群数据库上下文 ClusterDBContext\n@Slf4j public class ClusterDBContext { private static final ThreadLocal\u0026lt;String\u0026gt; dbContext = new ThreadLocal\u0026lt;\u0026gt;(); private static final AtomicInteger counter = new AtomicInteger(-1); public static final Map\u0026lt;Object, Object\u0026gt; dataSources = new HashMap\u0026lt;\u0026gt;(); private static final List\u0026lt;String\u0026gt; masterKeys = new ArrayList\u0026lt;\u0026gt;(); private static final List\u0026lt;String\u0026gt; slaveKeys = new ArrayList\u0026lt;\u0026gt;(); public static void registry(String key, Object obj) { dataSources.put(key, obj); if (StringUtils.startsWith(key, \u0026#34;master\u0026#34;)) { masterKeys.add(key); } else { slaveKeys.add(key); } } public static Object getDefaultMaster() { if (masterKeys.isEmpty()) { throw new RuntimeException(\u0026#34;not found master datasource\u0026#34;); } return dataSources.get(masterKeys.get(0)); } public static void set(String dbType) { dbContext.set(dbType); } public static String get() { return dbContext.get(); } public static void master() { int index = counter.getAndIncrement() % masterKeys.size(); String slaveKey = masterKeys.get(index); log.debug(\u0026#34;change master datasource ,use {}\u0026#34;, slaveKey); set(slaveKey); } public static void slave() { if (slaveKeys.isEmpty()) { log.warn(\u0026#34;not found slave datasource,use master\u0026#34;); master(); return; } // 读库负载均衡(轮询方式) int index = counter.getAndIncrement() % slaveKeys.size(); String slaveKey = slaveKeys.get(index); log.debug(\u0026#34;change slave datasource ,use {}\u0026#34;, slaveKey); set(slaveKey); } } 创建springboot自动装配类\n@Setter @Configuration @ConfigurationProperties(prefix = \u0026#34;spring.datasource\u0026#34;) @ConditionalOnProperty(value = \u0026#34;spring.datasource.enable-cluster\u0026#34;, havingValue = \u0026#34;true\u0026#34;) public class DatasourceClusterConfig { private Map\u0026lt;String, DataSourceProperties\u0026gt; cluster = new HashMap\u0026lt;\u0026gt;(); @Bean public List\u0026lt;DataSource\u0026gt; dataSources(@Autowired DataSourceProperties dataSourceProperties) { List\u0026lt;DataSource\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); // 处理默认的master datasource ClusterDBContext.registry(\u0026#34;master0\u0026#34;, createDataSource(dataSourceProperties)); this.cluster.forEach((key, val) -\u0026gt; { DataSource dataSource2 = createDataSource(val); ClusterDBContext.registry(key, dataSource2); }); return list; } private DataSource createDataSource(DataSourceProperties properties) { DriverManagerDataSource dataSource = new DriverManagerDataSource(); dataSource.setUrl(properties.getUrl()); dataSource.setUsername(properties.getUsername()); dataSource.setPassword(properties.getPassword()); dataSource.setDriverClassName(properties.getDriverClassName()); return dataSource; } @Bean @Primary @DependsOn(\u0026#34;dataSources\u0026#34;) public DataSource routingDataSource() { RoutingDataSource routingDataSource = new RoutingDataSource(); routingDataSource.setDefaultTargetDataSource(ClusterDBContext.getDefaultMaster()); routingDataSource.setTargetDataSources(ClusterDBContext.dataSources); return routingDataSource; } @Bean public DataSourceAop dataSourceAop() { return new DataSourceAop(); } } 通过以上配置，在springboot启动的时候，会将routingDataSource作为默认的datasource运行。\n为达到动态切换数据源的目录，可以有两种方式：\n通过切面，自动对查询类、修改类方法自动切换数据源 定义 @Master 注解，所有被该注解修饰的类均使用master数据源 定义@Master\npublic @interface Master { } 定义切面\n@Aspect public class DataSourceAop { @Pointcut(\u0026#34;@annotation(top.jiangliuhong.olcp.common.annos.Master) \u0026#34; + \u0026#34;|| execution(* top.jiangliuhong.olcp.*.service..*.insert*(..)) \u0026#34; + \u0026#34;|| execution(* top.jiangliuhong.olcp.*.service..*.save*(..)) \u0026#34; + \u0026#34;|| execution(* top.jiangliuhong.olcp.*.service..*.add*(..)) \u0026#34; + \u0026#34;|| execution(* top.jiangliuhong.olcp.*.service..*.update*(..)) \u0026#34; + \u0026#34;|| execution(* top.jiangliuhong.olcp.*.service..*.edit*(..)) \u0026#34; + \u0026#34;|| execution(* top.jiangliuhong.olcp.*.service..*.delete*(..)) \u0026#34; + \u0026#34;|| execution(* top.jiangliuhong.olcp.*.service..*.remove*(..))\u0026#34;) public void writePointcut() { } @Pointcut(\u0026#34;!@annotation(top.jiangliuhong.olcp.common.annos.Master) \u0026#34; + \u0026#34;\u0026amp;\u0026amp; (execution(* top.jiangliuhong.olcp.*.service..*.select*(..)) \u0026#34; + \u0026#34;|| execution(* top.jiangliuhong.olcp.*.service..*.query*(..)) \u0026#34; + \u0026#34;|| execution(* top.jiangliuhong.olcp.*.service..*.get*(..)))\u0026#34;) public void readPointcut() { } @Before(\u0026#34;writePointcut()\u0026#34;) public void write() { ClusterDBContext.master(); } @Before(\u0026#34;readPointcut()\u0026#34;) public void read() { ClusterDBContext.slave(); } } 数据源配置\nspring: datasource: # 默认的配置将作为 master0 url: jdbc:mysql://127.0.0.1:10301/olcp?useUnicode=true\u0026amp;characterEncoding=utf-8\u0026amp;useSSL=false\u0026amp;allowPublicKeyRetrieval=true username: root password: root driver-class-name: com.mysql.cj.jdbc.Driver enable-cluster: true cluster: master1: url: jdbc:mysql://127.0.0.1:10302/olcp?useUnicode=true\u0026amp;characterEncoding=utf-8\u0026amp;useSSL=false\u0026amp;allowPublicKeyRetrieval=true username: root password: root driver-class-name: com.mysql.cj.jdbc.Driver slave0: url: jdbc:mysql://127.0.0.1:10303/olcp?useUnicode=true\u0026amp;characterEncoding=utf-8\u0026amp;useSSL=false\u0026amp;allowPublicKeyRetrieval=true username: root password: root driver-class-name: com.mysql.cj.jdbc.Driver slave2: url: jdbc:mysql://127.0.0.1:10303/olcp?useUnicode=true\u0026amp;characterEncoding=utf-8\u0026amp;useSSL=false\u0026amp;allowPublicKeyRetrieval=true username: root password: root driver-class-name: com.mysql.cj.jdbc.Driver 通过上面的切面配置，当方法名是select、query、get开头、没有被@Master修饰的方法或者是方法名不被writePointcut匹配时，将默认使用slave数据源\n参考链接：https://zhuanlan.zhihu.com/p/80350536\n"},{"id":9,"href":"/docs/database/es/","title":"ElasticSearch","section":"数据库","content":" ElasticSearch # TODO\n"},{"id":10,"href":"/docs/database/redis/","title":"Redis","section":"数据库","content":" Redis # "},{"id":11,"href":"/docs/java/","title":"Java","section":"Docs","content":" Java # TODO ： Java知识点图谱\n"},{"id":12,"href":"/docs/database/mysql/storage/","title":"数据存储","section":"MySQL","content":" 数据存储 # 以InnoDB为例，InnoDB 是将数据存储在磁盘中，需要处理数据时，再将数据读取到内存中进行处理，对于 InnoDB 引擎会将数据划分为若干页，以页做为磁盘和内存交互的基本单位。InnoDB中页的大小一般为16KB。\n在MySQL服务运行的过程中不可以修改页的大小，只能在初始化数据目录的时候指定。\n存储的文件 # 假设目前存在一个数据库为testdb，在数据库中存在一个表为user，那么在MySQL 的数据目录/var/lib/mysql下将会存在这样的目录\n|-- testdb |-- db.opt |-- user.frm |-- user.ibd db.opt，用来存储当前数据库的默认字符集和字符校验规则。 t_order.frm ，t_order 的表结构会保存在这个文件。在 MySQL 中建立一张表都会生成一个.frm 文件，该文件是用来保存每个表的元数据信息的，主要包含表结构定义。 t_order.ibd，t_order 的表数据会保存在这个文件。表数据既可以存在共享表空间文件（文件名：ibdata1）里，也可以存放在独占表空间文件（文件名：表名字.idb）。这个行为是由参数 innodb_file_per_table 控制的，若设置了参数 innodb_file_per_table 为 1，则会将存储的数据、索引等信息单独存储在一个独占表空间，从 MySQL 5.6.6 版本开始，它的默认值就是 1 了，因此从这个版本之后， MySQL 中每一张表的数据都存放在一个独立的 .idb 文件。 存储文件结构 # 表空间由段（segment）、区（extent）、页（page）、行（row）组成，InnoDB存储引擎的逻辑存储结构大致如图：\n行：数据库表中的记录都是按行（row）进行存放的，每行记录根据不同的行格式，有不同的存储结构。\n页：\n记录是按照行来存储的，但是数据库的读取并不以「行」为单位，否则一次读取（也就是一次 I/O 操作）只能处理一行数据，效率会非常低。\nInnoDB 的数据是按「页」为单位来读写的，也就是说，当需要读一条记录的时候，并不是将这个行记录从磁盘读出来，而是以页为单位，将其整体读入内存。\n默认每个页的大小为 16KB，也就是最多能保证 16KB 的连续存储空间。\n区：\nB+ 树中每一层都是通过双向链表连接起来的，如果是以页为单位来分配存储空间，那么链表中相邻的两个页之间的物理位置并不是连续的，可能离得非常远，那么磁盘查询时就会有大量的随机I/O，随机 I/O 是非常慢的。\n解决办法就是让链表中相邻的页的物理位置也相邻，这样就可以使用顺序 I/O 了，那么在范围查询（扫描叶子节点）的时候性能就会很高。\n在表中数据量大的时候，为某个索引分配空间的时候就不再按照页为单位分配了，而是按照区（extent）为单位分配。每个区的大小为 1MB，对于 16KB 的页来说，连续的 64 个页会被划为一个区，这样就使得链表中相邻的页的物理位置也相邻，就能使用顺序 I/O 了。\n段：表空间是由各个段（segment）组成的，段是由多个区（extent）组成的。段一般分为数据段、索引段和回滚段等。\n索引段：存放 B + 树的非叶子节点的区的集合； 数据段：存放 B + 树的叶子节点的区的集合； 回滚段：存放的是回滚数据的区的集合 InnoDB 行格式 # 行格式（row_format）：一条数据记录在磁盘上的存储结构。\nInnoDB 提供了 4 种行格式，分别是 Redundant、Compact、Dynamic和 Compressed 行格式。\n我们可以在创建表或者修改表的语句中指定所使用的行格式\ncreate table \u0026#39;table info ..\u0026#39; row_format = \u0026#39;行格式名称\u0026#39; alter table \u0026#39;table name\u0026#39; row_format = \u0026#39;行格式名称\u0026#39; InnoDB 提供了 4 种行格式，分别是 Redundant、Compact、Dynamic和 Compressed 行格式：\nCompact（默认）： COMPACT是MySQL的默认行格式，它对于读密集型的工作负载通常表现良好。它采用变长的存储方式，并且对于短字段使用前缀压缩。 Redundant： REDUNDANT行格式使用了更多的存储空间，但在某些特殊情况下可能提供更好的性能。它通常用于处理特定的事务性工作负载。 Dynamic： DYNAMIC行格式采用变长字段，但相较于COMPACT，它对于短字段的压缩更为灵活，因此在某些情况下可能会更加节省空间。 Compressed： BARRACUDA是一种文件格式，而不是行格式。在MySQL 5.6之后的版本，InnoDB引擎引入了支持动态格式的文件格式BARRACUDA。 其中Compressed与Redundant存储格式与Compact相似；Redundant是一种古老的格式，如今使用微乎其微。\nCompact格式主要分为两部分：记录额外信息、记录的真是数据，如图：\n记录的额外信息 # 记录的额外信息包含 3 个部分：变长字段长度列表、NULL 值列表、记录头信息。\n变长字段长度列表 # 在存储数据的时候，需要要把数据占用的大小存起来，存到「变长字段长度列表」里面，读取数据的时候才能根据这个「变长字段长度列表」去读取对应长度的数据。VARCHAR、TEXT、BLOB 等变长字段都是这样实现的。\n首先创建一个表t_user并插入数据\nCREATE TABLE `t_user` ( `id` int(11) NOT NULL, `name` VARCHAR(20) NOT NULL, `phone` VARCHAR(20) DEFAULT NULL, `age` int(11) DEFAULT NULL, PRIMARY KEY (`id`) USING BTREE ) ENGINE = InnoDB DEFAULT CHARACTER SET = ascii ROW_FORMAT = COMPACT; insert into t_user values (1,\u0026#39;a\u0026#39;,\u0026#39;123\u0026#39;,18),(2,\u0026#39;bb\u0026#39;,\u0026#39;1234\u0026#39;,null),(3,\u0026#39;ccc\u0026#39;,null,null) 现在t_user表的数据为：\nid|name|phone|age| --+----+-----+---+ 1|a |123 | 18| 2|bb |1234 | | 3|ccc | | | 对于第一条数据而言：\nname 列的值为 a，真实数据占用的字节数是 1 字节，十六进制 0x01； phone 列的值为 123，真实数据占用的字节数是 3 字节，十六进制 0x03； 这些变长字段的真实数据占用的字节数会按照列的顺序逆序存放（为什么要逆序存放），所以「变长字段长度列表」里的内容是「 03 01」，而不是 「01 03」。\n第二条记录的行格式中，「变长字段长度列表」里的内容是「 04 02」\n第三条记录中 phone 列的值是 NULL，NULL 是不会存放在行格式中记录的真实数据部分里的，所以「变长字段长度列表」里不需要保存值为 NULL 的变长字段的长度。\n为什么逆序存放 # 当 InnoDB 存储引擎处理一行数据时，它通常是从行的末尾开始向前处理的。这是因为行的末尾通常包含了一些固定长度的信息（如行ID、事务ID等），这些信息的位置是固定的，因此可以很容易地找到。而变长字段则位于这些固定长度信息的前面。\n如果按照列的顺序直接存放变长字段的长度值，那么 InnoDB 在处理变长字段时就需要从行的开头开始逐个读取长度值，直到找到目标字段的长度。这样做可能会涉及到多次的磁盘块读写操作，因为每个字段的长度值可能分散在不同的磁盘块中。\n但是，如果按照列的顺序逆序存放这些长度值，InnoDB 就可以在处理变长字段时直接从行的末尾开始读取长度值。由于长度值是逆序存放的，因此目标字段的长度值会更快地被找到。这样，InnoDB 就可以更快速地定位到目标字段的数据在磁盘块中的位置，从而减少磁盘 I/O 操作的次数。\n记录头信息 # 记录头信息是由固定的5个字节组成，5个字节也就是40个二进制位，不同的位代表不同的意思，这些头信息会在后面的一些功能中看到。\n名称 大小（单位：bit） 描述 预留位1 1 没有使用 预留位2 1 没有使用 delete_mask 1 标识此条数据是否被删除。从这里可以知道，我们执行 detele 删除记录的时候，并不会真正的删除记录，只是将这个记录的 delete_mask 标记为 1 min_rec_mask 1 B+树的每层非叶子节点中的最小记录标记为1 n_owned 4 当前记录拥有的记录数 heap_no 13 索引堆中该条记录的排序记录 record_ type 3 记录类型，000（0）表示普通记录，001（1）表示B+树非叶子节点记录，010（2）表示最小记录，011（3）表示最大记录 next_record 16 下一条记录的位置。从这里可以知道，记录与记录之间是通过链表组织的。在前面我也提到了，指向的是下一条记录的「记录头信息」和「真实数据」之间的位置，这样的好处是向左读就是记录头信息，向右读就是真实数据，比较方便 Total 40 其中比较重要的是：delete_mask、delete_mask、record_type\nNULL 值列表 # 表中的某些列可能会存储 NULL 值，如果把这些 NULL 值都放到记录的真实数据中会比较浪费空间，所以 Compact 行格式把这些值为 NULL 的列存储到 NULL值列表中。\n如果存在允许 NULL 值的列，则每个列对应一个二进制位（bit），二进制位按照列的顺序逆序排列。\n二进制位的值为1时，代表该列的值为NULL。 二进制位的值为0时，代表该列的值不为NULL。 另外，NULL 值列表必须用整数个字节的位表示（1字节8位），如果使用的二进制位个数不足整数个字节，则在字节的高位补 0。\n以上面的t_user数据为例：\n列数据：\nid|name|phone| age | --+----+-----+----+ 1|a |123 | 18 | 2|bb |1234 |NULL| 3|ccc |NULL |NULL| 对于第一条记录，所有列都有值，不存在 NULL 值，所以用二进制来表示如下图所示：\n但是 InnoDB 是用整数字节的二进制位来表示 NULL 值列表的，现在不足 8 位，所以要在高位补 0，最终用二进制来表示是下面这样的：\n下面来看第二条记录， age 列是 NULL 值，所以，对于第二条数据，NULL值列表用十六进制表示是 0x04。\n最后第三条记录， phone 列 和 age 列是 NULL 值，所以，对于第三条数据，NULL 值列表用十六进制表示是 0x06。\n当三条记录的 NULL 值列表都填充完毕后，它们的行格式最终是这样的：\n记录的真实数据 # 记录真实数据部分除了我们定义的字段，还有三个隐藏字段，分别为：row_id、trx_id、roll_pointer\nrow_id:如果我们建表的时候指定了主键或者唯一约束列，那么就没有 row_id 隐藏字段了。如果既没有指定主键，又没有唯一约束，那么 InnoDB 就会为记录添加 row_id 隐藏字段。row_id不是必需的，占用 6 个字节。\ntrx_id:事务id，表示这个数据是由哪个事务生成的。 trx_id是必需的，占用 6 个字节。\nroll_pointer:这条记录上一个版本的指针。roll_pointer 是必需的，占用 7 个字节。\n其中trx_id 和 roll_pointer主要在MVCC 机制中起作用：MVCC机制\n行溢出处理 # MySQL 中磁盘和内存交互的基本单位是页，一个页的大小一般是 16KB，也就是 16384字节，而一个 varchar(n) 类型的列最多可以存储 65532字节，一些大对象如 TEXT、BLOB 可能存储更多的数据，这时一个页可能就存不了一条记录。这个时候就会发生行溢出，多的数据就会存到另外的「溢出页」中。\n如果一个数据页存不了一条记录，InnoDB 存储引擎会自动将溢出的数据存放到「溢出页」中。在一般情况下，InnoDB 的数据都是存放在 「数据页」中。但是当发生行溢出时，溢出的数据会存放到「溢出页」中。\n当发生行溢出时，在记录的真实数据处只会保存该列的一部分数据，而把剩余的数据放在「溢出页」中，然后真实数据处用 20 字节存储指向溢出页的地址，从而可以找到剩余数据所在的页。大致如下图所示。\n上面这个是 Compact 行格式在发生行溢出后的处理。\nCompressed 和 Dynamic 这两个行格式和 Compact 非常类似，主要的区别在于处理行溢出数据时有些区别。\n这两种格式采用完全的行溢出方式，记录的真实数据处不会存储该列的一部分数据，只存储 20 个字节的指针来指向溢出页。而实际的数据都存储在溢出页中，看起来就像下面这样：\n参考链接：\nMySQL的null值是怎么存储的?\nMySQL 的 NULL 值是怎么存放的?\n"},{"id":13,"href":"/docs/database/mysql/trans/","title":"事务","section":"MySQL","content":" 事务 # 事务 ACID 属性 # 事务是由一组SQL语句组成的逻辑处理单元,事务具有以下4个属性,通常简称为事务的ACID属性。\n1、原子性(Atomicity)\n事务是一个原子操作单元,其对数据的修改,要么全都执行,要么全都不执行。\n2、一致性(Consistent)\n在事务开始和完成时,数据都必须保持一致状态。这意味着所有相关的数据规则都必须应用于事务的修改,以保持数据的完整性;事务结束时,所有的内部数据结构(如B树索引或双向链表)也都必须是正确的。\n3、隔离性(Isolation)\n数据库系统提供一定的隔离机制,保证事务在不受外部并发操作影响的“独立”环境执行。这意味着事务处理过程中的中间状态对外部是不可见的,反之亦然。\n4、持久性(Durable)\n事务完成之后,它对于数据的修改是永久性的,即使出现系统故障也能够保持。\n隔离级别 # MySQL 事务隔离级别分为 4 个：\nREAD UNCOMMITTED：读未提交。 READ COMMITTED：读已提交。 REPEATABLE READ：可重复读。 SERIALIZABLE：序列化。 READ UNCOMMITTED # 读取未提交的数据，该隔离级别的事务可以看到其他事务下未提交的数据。\n同时由于未提交的数据可能会发生回滚，因此我们把该级别读取到的数据称之为脏数据，把这个问题称之为脏读。\nREAD COMMITTED # 读取已提交的数据，所有的数据都是已提交的，所以不会出现脏读的情况，但由于在不同事务中可以读取到其他事务已提交的数据，所以在不同的sql中，可能出现读取的数据不一致的情况，这种情况叫做不可重复读。\nREPEATABLE READ # 可重复度，这是 MySQL 默认的事务隔离级别，该隔离级别可以解决 READ COMMITED 所产生的不可重复读问题，但由于同一个事务的不同时间点，使用同一个 SQL 查询数据时，可能出现不同的结果，这种情况叫做幻读。\n一个典型的例子：\n执行sql：\nselect id,name from user 第一次执行结果：\nid name 1 test1 第一次执行结果：\nid name 1 test1 2 test2 其中，id 为 2 记录则是一个幻读的行\nSERIALIZABLE # 序列化，这是 MySQL 事务隔离级别中最高的级别，它会强制事务排序，使之不会发生冲突，从而解决了脏读、不可重复读和幻读问题，但因为执行效率低，所以真正使用的场景并不多。\n幻读和不可重复读区别 # 幻读和不可重复读的侧重点不同的：\n不可重复读侧重于数据修改，两次读取到的同一行数据不一样。 幻读侧重于添加或删除，两次查询返回的数据行数不同。 不同隔离级别总结 # 隔离级别 脏读 不可重复读 幻读 READ UNCOMMITTED Y Y Y READ COMMITTED N Y Y REPEATABLE READ N N Y SERIALIZABLE｜N N N 隔离级别实现方式 # MySQL 的隔离级别基于锁和 MVCC 机制共同实现的。\nSERIALIZABLE 隔离级别是通过锁来实现的，READ-COMMITTED 和 REPEATABLE-READ 隔离级别是基于 MVCC 实现的。不过， SERIALIZABLE 之外的其他隔离级别可能也需要用到锁机制，就比如 REPEATABLE-READ 在当前读情况下需要使用加锁读来保证不会出现幻读。\n如何选择隔离级别 # 在选择隔离级别时，需要根据应用的需求和场景进行权衡。如果需要较高的并发性能，可以选择较低的隔离级别，但需注意可能出现的数据一致性问题。如果数据一致性是首要考虑因素，可选择较高的隔离级别，但需要牺牲一些并发性能。\n一般来说，大多数应用会使用默认的隔离级别（通常是REPEATABLE READ），并根据具体情况对特定的事务调整隔离级别。\n注意，在使用较高隔离级别时，可能需要更多的数据库锁定，这可能会影响性能。因此，需要在保证数据一致性的同时，权衡并发性能和资源开销。\nMVCC机制 # MVCC 就是多版本并发控制。MVCC 是一种并发控制的方法，一般在数据库管理系统中，实现对数据库的并发访问。\n为什么需要MVCC呢？\n数据库通常使用锁来实现隔离性。最原生的锁，锁住一个资源后会禁止其他任何线程访问同一个资源。但是很多应用的一个特点都是读多写少的场景，很多数据的读取次数远大于修改的次数，而读取数据间互相排斥显得不是很必要。所以就使用了一种读写锁的方法，读锁和读锁之间不互斥，而写锁和写锁、读锁都互斥。这样就很大提升了系统的并发能力。\n之后人们发现并发读还是不够，又提出了能不能让读写之间也不冲突的方法，就是读取数据时通过一种类似快照的方式将数据保存下来，这样读锁就和写锁不冲突了，不同的事务session会看到自己特定版本的数据。当然快照是一种概念模型，不同的数据库可能用不同的方式来实现这种功能。\nInnoDB与MVCC # MVCC只在 READ COMMITTED 和 REPEATABLE READ 两个隔离级别下工作。其他两个隔离级别够和MVCC不兼容, 因为 READ UNCOMMITTED 总是读取最新的数据行, 而不是符合当前事务版本的数据行。而 SERIALIZABLE 则会对所有读取的行都加锁。\n主要的日志有三个：Redo log, bin log, Undo log\nInnoDB中通过undo log实现了数据的多版本，而并发控制通过锁来实现。\nbinlog：是mysql服务层产生的日志，常用来进行数据恢复、数据库复制，常见的mysql主从架构，就是采用slave同步master的binlog实现的, 另外通过解析binlog能够实现mysql到其他数据源（如ElasticSearch)的数据复制。\nredo log：\n记录了数据操作在物理层面的修改，mysql中使用了大量缓存，缓存存在于内存中，修改操作时会直接修改内存，而不是立刻修改磁盘，当内存和磁盘的数据不一致时，称内存中的数据为脏页(dirty page)。 为了保证数据的安全性，事务进行中时会不断的产生redo log，在事务提交时进行一次flush操作，保存到磁盘中, redo log是按照顺序写入的，磁盘的顺序读写的速度远大于随机读写。 当数据库或主机失效重启时，会根据redo log进行数据的恢复，如果redo log中有事务提交，则进行事务提交修改数据。这样实现了事务的原子性、一致性和持久性。 undo log:\n除了实现MVCC外，还用于事务的回滚。MySQL Innodb中存在多种日志，除了错误日志、查询日志外，还有很多和数据持久性、一致性有关的日志。 除了记录redo log外，当进行数据修改时还会记录undo log，undo log用于数据的撤回操作，它记录了修改的反向操作，比如，插入对应删除，修改对应修改为原来的数据，通过undo log可以实现事务回滚，并且可以根据undo log回溯到某个特定的版本的数据，实现MVCC。 版本链与Undo log # innodb中通过B+树作为索引的数据结构，并且主键所在的索引为ClusterIndex(聚簇索引), ClusterIndex中的叶子节点中保存了对应的数据内容。一个表只能有一个主键，所以只能有一个聚簇索引，如果表没有定义主键，则选择第一个非NULL唯一索引作为聚簇索引，如果还没有则生成一个隐藏id列作为聚簇索引。\n除了Cluster Index外的索引是Secondary Index(辅助索引)。辅助索引中的叶子节点保存的是聚簇索引的叶子节点的值。\nInnoDB行记录中除了刚才提到的rowid外，还有trx_id和db_roll_ptr, trx_id表示最近修改的事务的id,db_roll_ptr指向undo segment中的undo log。\n新增一个事务时事务id会增加，trx_id能够表示事务开始的先后顺序。\nUndo log分为Insert和Update两种，delete可以看做是一种特殊的update，即在记录上修改删除标记。\nupdate undo log记录了数据之前的数据信息，通过这些信息可以还原到之前版本的状态。\n当进行插入操作时，生成的Insert undo log在事务提交后即可删除，因为其他事务不需要这个undo log。\n进行删除修改操作时，会生成对应的undo log，并将当前数据记录中的db_roll_ptr指向新的undo log。\nReadView # 已提交读和可重复读的区别就在于它们生成ReadView的策略不同。\nReadView中主要就是有个列表来存储我们系统中当前活跃着的读写事务，也就是begin了还未提交的事务。通过这个列表来判断记录的某个版本是否对当前事务可见。其中最主要的与可见性相关的属性如下：\nup_limit_id：当前已经提交的事务号 + 1，事务号 \u0026lt; up_limit_id ，对于当前Read View都是可见的。理解起来就是创建Read View视图的时候，之前已经提交的事务对于该事务肯定是可见的。\nlow_limit_id：当前最大的事务号 + 1，事务号 \u0026gt;= low_limit_id，对于当前Read View都是不可见的。理解起来就是在创建Read View视图之后创建的事务对于该事务肯定是不可见的。\ntrx_ids：为活跃事务id列表，即Read View初始化时当前未提交的事务列表。所以当进行RR读的时候，trx_ids中的事务对于本事务是不可见的（除了自身事务，自身事务对于表的修改对于自己当然是可见的）。理解起来就是创建RV时，将当前活跃事务ID记录下来，后续即使他们提交对于本事务也是不可见的。\n假如存在表user，其中数据如下：\nid|name|trx_id|db_roll_ptr| --+----+------+-----------+ 1|MVCC| 50|上版本地址 | 执行sql:\nupdate user set name = \u0026#39;MVCC2\u0026#39; where id = 1; 此时undo log存在版本链如下:\n提交事务id是60的记录后，接着有一个事务id为100的事务，修改name=MVCC3，但是事务还没提交。则此时的版本链是：\n此时另一个事务发起select语句查询id=1的记录，因为trx_ids当前只有事务id为100的，所以该条记录不可见，继续查询下一条，发现trx_id=60的事务号小于up_limit_id，则可见，直接返回结果MVCC2。\n那这时候我们把事务id为100的事务提交了，并且新建了一个事务id为110也修改id为1的记录name=MVCC4，并且不提交事务。这时候版本链就是：\n这时候之前那个select事务又执行了一次查询,要查询id为1的记录。\n如果你是已提交读隔离级别READ_COMMITED，这时候你会重新一个ReadView，那你的活动事务列表中的值就变了，变成了[110]。按照上的说法，你去版本链通过trx_id对比查找到合适的结果就是MVCC4。\n如果你是可重复读隔离级别REPEATABLE_READ，这时候你的ReadView还是第一次select时候生成的ReadView,也就是列表的值还是[100]。所以select的结果是MVCC3。所以第二次select结果和第一次一样，所以叫可重复读！\n也就是说已提交读隔离级别下的事务在每次查询的开始都会生成一个独立的ReadView,而可重复读隔离级别则在第一次读的时候生成一个ReadView，之后的读都复用之前的ReadView。\n这就是Mysql的MVCC,通过版本链，实现多版本，可并发读-写，写-读。通过ReadView生成策略的不同实现不同的隔离级别。\n参考链接：\n一文理解Mysql MVCC\n"},{"id":14,"href":"/docs/database/mysql/normal/","title":"常见面试题","section":"MySQL","content":" 常见面试题 # 百万级大数据分页查询 # 首先模拟一张100万条记录的表：\n-- 创建表 CREATE TABLE IF NOT EXISTS sys_app ( id varchar(32) not null, name VARCHAR(30) NOT NULL unique, title VARCHAR(200) NOT NULL, create_time datetime, update_time datetime, create_user varchar(32), update_user varchar(32), PRIMARY KEY (id) ) ENGINE = InnoDB DEFAULT CHARSET = utf8; -- 插入数据 INSERT INTO sys_app (id, name, title, create_time, update_time, create_user, update_user) SELECT REPLACE(UUID(), \u0026#39;-\u0026#39;, \u0026#39;\u0026#39;), CONCAT(\u0026#39;App\u0026#39;, CAST(@counter := @counter + 1 AS CHAR(10))), CONCAT(\u0026#39;Title\u0026#39;, FLOOR(RAND() * 1000000)), NOW(), NOW(), \u0026#39;admin\u0026#39;, \u0026#39;admin\u0026#39; FROM (SELECT NULL) AS dummy JOIN (SELECT @counter := 0) AS init CROSS JOIN ( SELECT a.N + b.N * 10 + c.N * 100 + d.N * 1000 + e.N * 10000 + f.N * 100000 + g.N * 1000000 AS num FROM (SELECT 0 AS N UNION SELECT 1 UNION SELECT 2 UNION SELECT 3 UNION SELECT 4 UNION SELECT 5 UNION SELECT 6 UNION SELECT 7 UNION SELECT 8 UNION SELECT 9) AS a CROSS JOIN (SELECT 0 AS N UNION SELECT 1 UNION SELECT 2 UNION SELECT 3 UNION SELECT 4 UNION SELECT 5 UNION SELECT 6 UNION SELECT 7 UNION SELECT 8 UNION SELECT 9) AS b CROSS JOIN (SELECT 0 AS N UNION SELECT 1 UNION SELECT 2 UNION SELECT 3 UNION SELECT 4 UNION SELECT 5 UNION SELECT 6 UNION SELECT 7 UNION SELECT 8 UNION SELECT 9) AS c CROSS JOIN (SELECT 0 AS N UNION SELECT 1 UNION SELECT 2 UNION SELECT 3 UNION SELECT 4 UNION SELECT 5 UNION SELECT 6 UNION SELECT 7 UNION SELECT 8 UNION SELECT 9) AS d CROSS JOIN (SELECT 0 AS N UNION SELECT 1 UNION SELECT 2 UNION SELECT 3 UNION SELECT 4 UNION SELECT 5 UNION SELECT 6 UNION SELECT 7 UNION SELECT 8 UNION SELECT 9) AS e CROSS JOIN (SELECT 0 AS N UNION SELECT 1 UNION SELECT 2 UNION SELECT 3 UNION SELECT 4 UNION SELECT 5 UNION SELECT 6 UNION SELECT 7 UNION SELECT 8 UNION SELECT 9) AS f CROSS JOIN (SELECT 0 AS N UNION SELECT 1 UNION SELECT 2 UNION SELECT 3 UNION SELECT 4 UNION SELECT 5 UNION SELECT 6 UNION SELECT 7 UNION SELECT 8 UNION SELECT 9) AS g ) AS nums LIMIT 10000000; 执行一次深分页查询：\nselect * from sys_app where name like \u0026#39;App1%\u0026#39; limit 999999,10 ; 耗时： 1 s 228 ms\n优化一：基于索引再排序\n利用MySQL支持ORDER操作可以利用索引快速定位部分元组,避免全表扫描\nselect * from sys_app where id in (select id from (select id from sys_app where name like \u0026#39;App1%\u0026#39; order by id limit 999999,10 ) t ) 耗时：607 ms\n如果id是自增id,同时也没有额外的查询条件，也可以使用下面的方式：\nselect * from sys_app table WHERE id\u0026gt;=10000 ORDER BY id ASC LIMIT 0,20 对于有额外查询条件，需要对额外查询条件增加索引此方法才能生效\n优化二：利用子查询/连接+索引快速定位元组的位置,然后再读取元组.\nSELECT a.* FROM sys_app a JOIN (select id from sys_app limit 999999,10) b ON a.id = b.id 耗时：135 ms\n补充总结：\nmysql数据表记录数超过几十万时，使用limit进行分页，性能会比较差 mysql推荐使用自增id作为数据表的主键，不要使用uuid作为数据表的主键 mysql表的索引会影响查询的默认排序，并不绝对是按主键排序 分布式情况下推荐使用带时间属性的自增长id(分布式自增长id算法) 参考：https://www.jianshu.com/p/029070a3ca83\nMySQL 怎么知道 varchar(n) 实际占用数据的大小 # MySQL 的 Compact 行格式中会用「变长字段长度列表」存储变长字段实际占用的数据大小。\nvarchar(n) 中 n 最大取值为多少 # 我们要清楚一点，MySQL 规定除了 TEXT、BLOBs 这种大对象类型之外，其他所有的列（不包括隐藏列和记录头信息）占用的字节长度加起来不能超过 65535 个字节。\n也就是说，一行记录除了 TEXT、BLOBs 类型的列，限制最大为 65535 字节，注意是一行的总长度，不是一列。\n知道了这个前提之后，我们再来看看这个问题：「varchar(n) 中 n 最大取值为多少？」\nvarchar(n) 字段类型的 n 代表的是最多存储的字符数量，并不是字节大小哦。\n要算 varchar(n) 最大能允许存储的字节数，还要看数据库表的字符集，因为字符集代表着，1个字符要占用多少字节，比如 ascii 字符集， 1 个字符占用 1 字节，那么 varchar(100) 意味着最大能允许存储 100 字节的数据。\n首先根据MySQL行格式可以知道varchar(n)存储分为三部分：\n真实数据 真实数据占用的字节数 NULL 标识，如果不允许为NULL，这部分不需要 所以可以得出下面的公式：\nn 的最大值 = 65535 -（「变长字段长度列表」「NULL 值列表」所占用的字节数）\n注意，上面的仅为单字段的计算公式，如果是多字段的话，要保证所有字段的长度 + 变长字段字节数列表所占用的字节数 + NULL值列表所占用的字节数 \u0026lt;= 65535。\n行溢出后，MySQL 是怎么处理的 # 如果一个数据页存不了一条记录，InnoDB 存储引擎会自动将溢出的数据存放到「溢出页」中。\nCompact 行格式针对行溢出的处理是这样的：当发生行溢出时，在记录的真实数据处只会保存该列的一部分数据，而把剩余的数据放在「溢出页」中，然后真实数据处用 20 字节存储指向溢出页的地址，从而可以找到剩余数据所在的页。\nCompressed 和 Dynamic 这两种格式采用完全的行溢出方式，记录的真实数据处不会存储该列的一部分数据，只存储 20 个字节的指针来指向溢出页。而实际的数据都存储在溢出页中。\nnull值相关问题 # null 值引发的坑有哪些 # 精度丢失： 在进行count()或count(列)时，可能出现结果不一致的问题。count(列)自动去除结果为NULL的列，导致可能出现count(列)小于count()的情况。使用count带distinct同样可能引发精度缺失，例如select count(id,name)，当name为NULL时，select count(distinct id,name)的值会变小。\nnull值对比永远为false： 所有与NULL值的比较（大于、小于、等于）的结果都为false。对于NULL值的比较，必须使用IS NULL、IS NOT NULL或ISNULL函数。ISNULL函数相比其他两者效率较高。\nnull值与其他进行运算结果均为null： 在加减乘除等运算中，NULL值与其他值进行操作的结果均为NULL。使用concat函数拼接NULL值的结果也为NULL。\nSUM引发空指针问题： 使用SUM(NULL)会导致空指针错误。\nGROUP BY、ORDER BY不会过滤NULL值： 在使用GROUP BY或ORDER BY时，NULL值不会被过滤，可能影响结果的排序和分组。\n变长字段长度列表为什么逆序存放 # 因为「记录头信息」中指向下一个记录的指针，指向的是下一条记录的「记录头信息」和「真实数据」之间的位置，这样的好处是向左读就是记录头信息，向右读就是真实数据，比较方便。\n「变长字段长度列表」中的信息之所以要逆序存放，是因为这样可以使得位置靠前的记录的真实数据和数据对应的字段长度信息可以同时在一个 CPU Cache Line 中，这样就可以提高 CPU Cache 的命中率。\n同样的道理， NULL 值列表的信息也需要逆序存放。\n每个数据库表的行格式都有「NULL 值列表」吗？ # NULL 值列表也不是必须的。\n当数据表的字段都定义成 NOT NULL 的时候，这时候表里的行格式就不会有 NULL 值列表了。所以在设计数据库表的时候，通常都是建议将字段设置为 NOT NULL，这样可以节省 1 字节的空间（NULL 值列表占用 1 字节空间）。\nnull 值空间问题 # null 值会占用空间吗？\n会的，因为一个字段需要用 1 字节来表示「NULL 值列表」，而一个字节可以表示 8 个 NULL 值\n所以占用空间为： Math.ceil((double)NULL字段个数/8) 字节。\n「NULL 值列表」是固定 1 字节空间吗？\n「NULL 值列表」的空间不是固定 1 字节的。\n一条记录有 9 个字段值都是 NULL，这时候怎么表示？\n当一条记录有 9 个字段值都是 NULL，那么就会创建 2 字节空间的「NULL 值列表」，以此类推。\n分库分表 # 什么是分库分表 # 一种数据库架构设计模式，主要用于解决由于数据量过大而导致数据库性能降低的问题。它将原来独立的数据库拆分成若干数据库组成，将数据大表拆分成若干数据表组成，使得单一数据库、单一数据表的数据量变小，从而达到提升数据库性能的目的。在生产环境中，分库分表通常包括垂直分库、水平分库、垂直分表、水平分表四种方式。\n垂直分库是根据业务耦合性，将关联度低的不同表存储在不同的数据库。做法与大系统拆分为多个小系统类似，按业务分类进行独立划分。与\u0026quot;微服务治理\u0026quot;的做法相似，每个微服务使用单独的一个数据库。\n水平分库则是把一个表的数据分到多个库中，每个库的结构都一样，每个库的数据都不一样，没有交集。库所有的表都没有主键，主键由每个库的库名+每个表的主键组成。\n垂直分表是将一张宽表按列拆分成多张表的过程。原始表中的某些列被分离出来，形成新的表，而新表与原始表通过主键相互关联。这种拆分通常基于列的访问频率、数据大小或业务逻辑来进行。\n示例：\n假设有一个用户表（user），包含以下列：id、username、password、email、phone、address、bio。如果address和bio字段通常不一起访问，且包含大量文本数据，可以考虑将它们拆分到另一张表中。\n拆分后可能得到两张表：\nuser_core：包含id、username、password、email、phone。 user_profile：包含user_id（与user_core的id对应）、address、bio。 优点：\n减少IO负担，因为可以只读取需要的列。 某些列的数据类型或大小可能更适合单独的存储或索引策略。 缺点：\n需要管理冗余的主键或外键。 事务处理可能变得复杂，特别是当需要在多个表之间保持数据一致性时。 查询可能需要跨多个表进行，增加了查询的复杂性。 水平分表是将一张表的数据行按照某种规则（如哈希、范围、目录等）分布到多个结构相同的表中。每个表都包含原始表的一部分数据，但表结构保持一致。\n示例：\n假设有一个订单表（orders），随着业务增长，该表的数据量变得非常庞大。为了分散负载和提高性能，可以将订单数据按照订单ID的范围或哈希值分布到多个表中，如orders_001、orders_002、orders_003等。\n优点：\n解决了单一表数据量过大的问题。 可以将不同表分布在不同的物理存储上，提高IO性能。 易于扩展，只需添加更多的表即可容纳更多的数据。 缺点：\n事务一致性难以维护，特别是当事务涉及多个分表时。 跨多个表的查询和报表生成可能变得复杂和低效。 数据迁移、备份和恢复可能更加困难。 需要额外的逻辑来管理数据的分布和路由。 怎样分库分表 # 首选需要搞懂，为什么需要分库分表，分库分表主要为了解决数据量过大时的数据库瓶颈问题，例如：\n数据库资源不足：在高并发的业务场景下，大量的用户请求需要同时访问数据库，如果数据库连接数有限，就会导致部分请求无法获得数据库连接而阻塞。通过分库，可以将请求分散到不同的数据库中，从而减轻单个数据库的连接压力。 磁盘 IO 瓶颈：当单个数据库的数据量过大时，磁盘IO会成为性能瓶颈。通过分库分表，可以将数据分散到多个数据库和表中，从而降低单个数据库和表的磁盘IO压力。 检索数据耗时：对于数据量极大的单表，即使使用了索引，查询效率也可能会非常低下。分表可以解决单表数据量过大导致的查询性能问题。通过将大表拆分成多个小表，可以降低查询时需要扫描的数据量，从而提高查询效率。 CPU 瓶颈：数据库在处理大量数据时，CPU资源也可能成为瓶颈。通过分库分表，可以将数据处理任务分散到多个数据库服务器上，从而充分利用多台服务器的CPU资源。 总体来说就是性能出现瓶颈，并且没有其他优化手段去进行优化（索引优化，增加从库等）时则需要考虑分库分表：\n单表瓶颈：单表数据量较大，导致读写性能较慢 单库出现瓶颈： CPU 压力过大（busy、load过大）导致读写性能较慢 内存不足（缓存命中低，磁盘 IO 过高）导致读写性能较慢 磁盘空间不足导致无法写入数据 网络带宽不足导致读写性能较慢 对于分库分表又分多种情况：\n只分表： 单表数据量较大 评估单库容量和性能是否可以支撑未来几年的业务增长 只分库：数据库读写压力较大，数据库出现存储性能瓶颈 既分库又分表：同时具备以上两种特点，单表压力大，数据库读写压力大 亿级数据分库分表 # 评估 对于一个亿级系统，首先需要进行评估：需要拆分为几个库、几个表；读写能力需要提升多少倍、负载需要降低多少、数据库容量需要支持未来几年的发展。\n确定切分策略 其次需要确定切分策略，常见的策略有：范围切分、中间表映射、hash切分\n范围切分：根据某一个值的范围进行切分，支持水平扩展，单表大小可控。缺点是存在明显的读写偏移。\n写偏移：id一般是按顺序新增，所以所有某一段时间，写数据的操作会集中在某一张表上\n读偏移：一般情况下，新增的数据查下效率会较高\n中间表映射：将所有数据库和id的值维护在一张中间表中,每次查询时，先通过中间表确认查询来源。缺点是引入了额外的表，增加了复杂度，同时中间表可能会他别大，很难保证该表的性能，这种方法仅适用一些特殊的场景。\nhash切分：对目标key进行hash取模，从而判断数据要落到哪个库。使用hash切分，优点是数据分片比较均匀，不容易出现热点和并发访问的瓶颈。缺点是后续扩容需要迁移数据、存在跨节点查下问题。\n确定分表字段 分表字段选择应该尽量减少跨库跨表查询的出现。在选择分表字段时可以参考以下几点：\n覆盖的场景要尽可能多 一般是多个关联表的公共字段 可以采用基因算法融合字段 多种场景下，可以不用纠结把所有字段融合，可以采用冗余表的方法 进行代码改造 写入：单写老库 =\u0026gt; 双写 =\u0026gt; 单写新库 读取：读老库 =\u0026gt; 部分读老、部分读新 =\u0026gt; 读新库 灰度：根据业务场景，指定一部分灰度，或者按照比例进行灰度（这里的灰度是指到新库上进行测试） 其中双写是保证增量数据在新库和老库都存在，其中方案主要有一下几点：\n同步双写，同时写入老库和新库中，一般推荐使用aop进行实现 异步双写，写入老库，通过监听数据库变化（binlog）同步到新库，也可以使用同步工具，通过一定规则将数据同步到目标表 需要注意的是，在不停服进行改造的情况下，在进行存量数据同步的时候，也会进行增量同步，需要避免并发处理同一条数据，从而导致系统异常。\n数据一致性校验、优化、补偿 在进行数据库切换之前，需要保证新库数据完全正确，所以需要对新库进行增量数据校验、存量数据校验操作。\n只有校验通过才能进行数据库切换。\n灰度切换 灰度切换时必须保证一下原则：\n有问题随时可切回老库 灰度放量先慢后快，每次放量需要观察一段时间 灰度切换需要支持灵活的规则 完整的流程： 分库分表引发的问题 # 分布式唯一 ID UUID：本地生成，性能高；但UUID 更占用存储空间，并且不适合作为 MYSQL 主键（无序主键会导致磁盘随机 IO 较高，索引树变高） 雪花算法：41bit时间戳 10bit机器id 12bit序列号，每秒可生存 409 万个 号段模式，使用一个额外表的自增id作为分布式 id，每次读取数据看时调用数据库批量生成一批，放在缓存中进行使用 分布式事务 两阶段提交：\ntcc(try confirm cancel):\n最终一致性：回滚、重试、监控、告警、幂等、人工核查\n跨库JOIN/分页查询 选择合适的分表字段 引入搜索引擎 分开查询，内存中聚合 冗余字段 历史数据处理 对历史数据进行冷热处理，热数据存在mysql中，冷数据放在hbase或者tidb中\n"},{"id":15,"href":"/docs/database/mysql/","title":"MySQL","section":"数据库","content":" MySQL # "},{"id":16,"href":"/docs/database/","title":"数据库","section":"Docs","content":" 数据库 # TODO ： 数据库知识点图谱\n"},{"id":17,"href":"/docs/database/mysql/indexes/","title":"索引概率","section":"MySQL","content":" 索引概念 # 索引是什么 # 索引是对数据库表中一列或多列的值进行排序的一种数据结构，能实现快速定位数据的一种存储结构，其设计思想是以空间换时间。\n在关系型数据库中，索引是一种单独的、物理的对数据库表中的一列或者多列的值进行排序的一种存储结构，它是某个表中一列或若干列值的集合和相应的指向表中物理标识，这些值的数据页的逻辑指针清单。索引的作用相当于图书的目录，可以根据目录中的页码快速找到所需的内容。\n索引的分类 # 按数据结构分类：\nB+tree索引 Hash索引 Full-text 索引 按物理存储分类：\n聚簇索引（主键索引） 二级索引（辅助索引） 按字段特性分类：\n主键索引 唯一索引 普通索引 前缀索引 按字段个数分类：\n单列索引 联合索引 唯一索引 # 唯一索引和普通索引类似，主要区别在于，唯一索引限制列的值必须唯一，但允许存在空值（只能有一个）。主键索引不允许有空值。\n全文索引 # 在执行模糊查询的时候，如like \u0026quot;value%\u0026quot;，这种情况下，需要考虑使用全文搜索的方式进行优化。全文搜索在MySQL中是一个FULLTEXT类型索引。全文索引主要用来查找文本中的关键字，而不是直接与索引中的值进行比较，它更像是一个搜索引擎，而不是简单的where语句的参数匹配。目前只有char/vachar/text列上可以创建全文索引，默认Mysql不支持中文全文搜索。Mysql全文搜索只是一个临时方案，对于全文搜索场景，更专业的做法是使用全文搜索引擎，如ElasticSearch。\nHash 索引 # Hash索引是一种基于哈希算法的索引类型。它通过将索引键值通过哈希函数转换为固定长度的哈希码，然后将哈希码映射到实际存储位置。Hash索引适用于等值查询，例如在WHERE子句中使用=条件。Hash索引适用于等值查询的场景，但由于哈希碰撞（不同键值得到相同的哈希码）可能导致性能下降，因此在某些情况下不如B树索引。\n组合索引 # 组合索引是指在多个列上创建的索引，这样可以更有效地支持多列的查询条件。组合索引按照索引的列顺序建立，从左到右，左侧列的顺序性更强。当查询中涉及多个列作为查询条件时，组合索引能够更好地提高查询性能。但要注意，组合索引的列顺序要考虑到查询频率较高的列放在前面。\n聚簇索引与非聚簇索引 # 聚簇索引是一种特殊的索引，它决定了数据表中数据的物理排列顺序，使得索引和数据行保存在一起。InnoDB存储引擎中的主键索引就是聚簇索引。\n与聚簇索引相对应的是非聚簇索引。非聚簇索引中索引和数据行是分开存储的，索引仅包含指向实际数据行的指针。\n需要注意的是，当查询列不在非聚簇索引上时，会引发回表。\nMySQL 索引机制 # 为什么InnoDB要使用 B+ 树，而不是 B 树 # 首先，由于索引本身数据量大，所以只能以索引文件的形式存储在磁盘上，也就导致每次读取索引都会产生磁盘 I/O 消耗，所以选用的数据结构能获取更多的信息并且 I/O 消耗更低就尤为重要。\nB 树概念 # B 树是一种自平衡的二叉树，它维护有序数据并允许对树进行搜索、顺序访问、插入和删除。它是二叉搜索树的一种演化，在 B 树中，一个父节点可以有多个子节点。\nB 树是一种平衡的多分树，通常我们说 m 阶的 B 树，他必须满足如下条件：\n每个节点最多有 m 个子节点 每个非叶子节点（除去根节点）具有至少 m/2 个子节点 根节点至少有两个子节点 具有 k 个子节点的非叶子节点包含 k-1 个键 B 树的阶，指的是 B 树中节点的子节点数目的最大值。例如在上图的书中，「13,16,19」拥有的子节点数目最多，一共有四个子节点（灰色节点）。所以该 B 树的阶为 4，该树称为 4 阶 B 树。在实际应用中，B 树应用于 MongoDb 的索引。\nB+ 树概念 # B+ 树是由 B 树演变的，是使用文件系统使用的数据结构：\n有 m 个子树的中间节点包含有 m 个元素，每个元素不保持数据，只作为索引使用。 所有的叶子节点中包含了关键字的信息，以及这些关键字记录的指针，并且叶子节点本身按照关键字的大小从大到小的顺序排列。 与 B 树相比，B+ 树的有点为：\nB+ 树的磁盘读写代驾更低：B+ 树的内部节点并没有指向关键字的指针信息，所以内部节点所使用的空间更小，对于相同大小能存放的关键字信息就更多，所以一次读入内存的关键字也就更多，从而减少 I/O 次数。 B+ 树查询效率更加稳定：由于 B+ 非终节点并不实际指向文件内容，只是存储叶子节点的关键字索引，所以 B+ 树中任何关键字的查询必须从根节点查询到叶子节点，所有关键字的查询的遍历层级是相同的，也就是导致数据查询效率相当。 B+ 树更适合用于范围查找：对于遍历，B+ 树只需要遍历叶子节点就可以实现整棵树的遍历。 总结：\nB+树是一棵平衡树，每个叶子节点到根节点的路径长度相同，查找效率较高 B+树的所有关键字都在叶子节点上，因此范围查询时只需要遍历一遍叶子节点即可 B+树的叶子节点都按照关键字大小顺序存放，因此可以快速地支持按照关键字大小进行排序 B+树的非叶子节点不存储实际数据，因此可以存储更多的索引/数据； B+树的非叶子节点使用指针连接子节点，因此可以快速地支持范围查询和倒序查询 B+树的叶子节点之间通过双向链表链接，方便进行范围查询。 B+ 树与其他数据结构对比 # 与B 树：\nB 树非叶子节点也要存储数据，相同磁盘 IO，B+树能查询更多节点 B+树双向链表适合范围查询，B 树的中序遍历会更麻烦 二叉树：\nB+树查询时间复杂度为logdN,二叉树为logN B+树存储千万数据也需要二～三层，进行二～三次 IO，二叉树则 IO 更多 Hash：\nHash 无法进行范围查询 Hash维护索引成本更低 红黑树：\n红黑树是一种二叉搜索树，每个节点最多只能包含两个子节点 B树是一种多路搜索树，它的每个节点可以包含多个键值和子节点 红黑树更适用于实现集合和映射等数据结构，以及其它查找频繁的场景 B树更适用于实现数据库索引等需要频繁插入和删除操作的场景 高度为 3 的 B+ 树能存多少数据 # TODO\nInnoDB 与 MyISAM 引擎下的索引区别 # Innodb 中 B+ 树是如何产生的 # TODO\nInnodb 是如何支持范围查找能走索引的 # TODO\n索引下推 # 索引下推（ICP）是 MySQL5.6 针对扫描二级索引的一项优化改造。通过把索引过滤条件下推到存储引擎，来减少 MySQL 存储引擎访问基表的次数以及 MySQL 服务层访问存储引擎的次数。ICP 适用于 MYISAM 和 INNODB 引擎。\n认识mysql架构 # MySQL 服务层：也就是 SERVER 层，用来解析 SQL 的语法、语义、生成查询计划、接管从 MySQL 存储引/擎层上推的数据进行二次过滤等等。 MySQL 存储引擎层：按照 MySQL 服务层下发的请求，通过索引或者全表扫描等方式把数据上传到MySQL 服务层。 MySQL 索引扫描：根据指定索引过滤条件，遍历索引找到索引键对应的主键值后回表过滤剩余过滤条件。 MySQL 索引过滤：通过索引扫描并且基于索引进行二次条件过滤后再回表。 索引下推的作用 # 作用：减少回表次数\n现在以一个例子展示索引下推：\n-- 创建表 create table user ( id int primary key comment \u0026#39;id\u0026#39; , name varchar(20) comment \u0026#39;姓名\u0026#39;, age int comment \u0026#39;年龄\u0026#39;, card int comment \u0026#39;身份证\u0026#39;, key idx_name_age (name,age) )engine=InnoDB default charset=utf8mb4; -- 插入数据 insert into user values (1,\u0026#39;李四\u0026#39;,18,1),(2,\u0026#39;李五\u0026#39;,20,2),(3,\u0026#39;王五\u0026#39;,23,3),(4,\u0026#39;张三\u0026#39;,30,4); 查询执行计划：\nexplain select * from user where name like \u0026#39;李%\u0026#39; and age \u0026gt;= 18; -- 结果为：Using where 设置索引下推\nSET optimizer_switch=\u0026#39;index_condition_pushdown=on\u0026#39;; 再次查询执行记录\nexplain select * from user where name like \u0026#39;李%\u0026#39; and age \u0026gt;= 18; -- 结果为：Using index condition 从索引计划可以看出，执行计划打印为Using index condition则代表使用了索引下推。\n假设执行sql为select * from user where name like '李%' and age = 18，通过下面的图可以很明显的看见两种情况下的查询逻辑\n未使用索引下推时的查询：\n使用索引下推时的查询：\n命令总结：\n＃ 查看索引下推是否开启 select @@optimizer_switch #开启索引下推 SET optimizer_switch=\u0026#39;index_condition_pushdown=on\u0026#39;; # 关闭索引下推 SET optimizer_Switch=\u0026#34;index_condition_pushdown=off\u0026#34;; 索引下推的使用条件 # 索引下推的目标是减少全行记录读取，从而减少 IO 操作，只能用于非聚簇索引。（聚簇索引本身已包含行数据，不存在回表） 只能用于 range、ref、eq_ref、ref_or_null等操作 where条件中使用and的时候（or为排除记录，不需要查询行数据） 适用于分区表 不支持在虚拟列上建立索引（例如：函数索引） 不支持引用子查询作为查询条件 不支持存储函数作为条件，因为在存储引擎中无法调用存储函数 索引排序内部流程 # 索引失效 # 什么情况下索引失效 # 在MySQL8中，索引失效的场景有：\nlike查询左边带%时可能会失效 隐式类型转换，即索引字段与查询条件或关联字段类型不一致，MySQL会对其进行类型转换，从而导致索引失效 where条件中对索引列使用运算符或函数会导致失效 使用OR查询，并且存在非索引时会导致失效 使用IN查询可能会导致索引失效，在 MySQL 中，通过环境变量eq_range_index_dive_limt的值从而影响 IN查询，在 MySQL8 中，当该值 为 200 时，使用 IN 查询的条件个数大于 200则不会走索引 使用非主键进行范围查询时，可能会失效 使用order by可能会导致失效 is null、is not null ≠可能会失效 字段为 null 索引是否失效 # 在MySQL中，对于字段为null的情况，索引并不会失效，而是涉及到优化器的选择。MySQL会考虑走索引与不走索引的成本，并在执行查询时选择最优的执行计划。\n对于字段为null的情况，使用is null、is not null或 ≠条件，索引仍然可以被利用。优化器会计算索引扫描的成本以及回表操作的成本。如果走索引扫描的效率高于全表扫描，优化器将选择使用索引扫描，然后进行回表操作。\n需要注意的是，如果结果列的大小相对于行数量较小，优化器更倾向于执行索引扫描。这是因为索引扫描后再回表的成本相对较低。反之，如果结果列数量较大，那么索引扫描后再回表的效率可能远低于全表扫描，此时优化器可能选择不使用索引。\n因此，索引对于字段为null的情况并不失效，而是在优化器根据具体情况进行智能选择，以提高查询性能。\n首先is null、is not null ≠都是可以走索引的，在MySQL中，MySQL会计算走索引与不走索引的成本，因为如果走索引扫描，那么必然会存在回表操作，MySQL 会计算结果列的大小，如果结果列远低于行数量，那么优化器就会执行索引扫描，然后再回表查询数据，反之，如果结果列数量较大，那么索引扫描后再回表的效率就远低于全表扫描。\n关于mysql null值更详细的说明：null值的存储\nLIKE 索引失效问题 # 首先索引的数据结构是B+树，在 B+ 树中，数据是有序的，从下图中可以看出 4 个aba -\u0026gt; abb -\u0026gt; abc -\u0026gt; abc -\u0026gt; abe 是有序排列的，当输入条件为 like \u0026lsquo;a%\u0026lsquo;时，在 B+ 树中是有序查找，所以like前模糊匹配是可以走索引的，但如果缓存后模糊匹配，由于结尾并不是有序排列的，所以此时索引会失效。\n但是在某些特定情况，前模糊匹配也可能失效：\n-- 创建表 create table user ( id int primary key comment \u0026#39;id\u0026#39; , name varchar(20) comment \u0026#39;姓名\u0026#39;, card int comment \u0026#39;身份证\u0026#39;, key idx_name (name) )engine=InnoDB default charset=utf8mb4; -- 插入数据 insert into user values (1,\u0026#39;李四\u0026#39;,1),(2,\u0026#39;李五\u0026#39;,2),(3,\u0026#39;王五\u0026#39;,3),(4,\u0026#39;张三\u0026#39;,4); -- 创建表 create table user_exp( id int primary key comment \u0026#39;id\u0026#39;, name varchar(20) comment \u0026#39;姓名\u0026#39;, key idx_name (name) )engine=InnoDB default charset=utf8mb4; -- 插入数据 insert into user_exp values (1,\u0026#39;李四\u0026#39;),(2,\u0026#39;李五\u0026#39;),(3,\u0026#39;王五\u0026#39;),(4,\u0026#39;张三\u0026#39;); 执行：\nexplain select * from user where name like \u0026#39;%五\u0026#39;; 打印结果为：\nid|select_type|table|partitions|type|possible_keys|key|key_len|ref|rows|filtered|Extra | --+-----------+-----+----------+----+-------------+---+-------+---+----+--------+-----------+ 1|SIMPLE |user | |ALL | | | | | 4| 25.0|Using where| 执行：\nexplain select id,name from user where name like \u0026#39;%五\u0026#39;; 结果：\nid|select_type|table|partitions|type |possible_keys|key |key_len|ref|rows|filtered|Extra | --+-----------+-----+----------+-----+-------------+--------+-------+---+----+--------+------------------------+ 1|SIMPLE |user | |index| |idx_name|83 | | 4| 25.0|Using where; Using index| 执行：\nexplain select id,name from user where user_exp like \u0026#39;%五\u0026#39;; explain select * from user where user_exp like \u0026#39;%五\u0026#39;; 两个的结果均为：\nid|select_type|table |partitions|type |possible_keys|key |key_len|ref|rows|filtered|Extra | --+-----------+--------+----------+-----+-------------+--------+-------+---+----+--------+------------------------+ 1|SIMPLE |user_exp| |index| |idx_name|83 | | 4| 25.0|Using where; Using index| 对于上面的例子，首先我们需要查询的 id、 name 这两个字段都在我们的辅助索引中，叶子节点存的索引值和主键值，所以我们只要查辅助索引就可以直接拿到我们的需要的结果了，那么这个叫做索引|覆盖。我们观察执行计划会发现它的查询级别是 index，其实也是全表遍历了辅助索引。\n对于第一个例子，查询的是所有字段，而card字段不在辅助索引中，如果遍历辅助索引，则还需要回标，效率远没有直接遍历高。\n"}]